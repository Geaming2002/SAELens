{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0zLdMswKcLn1"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "REPO_DIR = f'sae_lens/sae_bench/ravel'\n",
    "SRC_DIR = os.path.join(REPO_DIR, 'src')\n",
    "MODEL_DIR = os.path.join(REPO_DIR, 'models')\n",
    "DATA_DIR = os.path.join(REPO_DIR, 'data')\n",
    "\n",
    "for d in [MODEL_DIR, DATA_DIR]:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(REPO_DIR)\n",
    "sys.path.append(SRC_DIR)\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import accelerate\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sae_lens.sae_bench.utils.generation_utils import generate_batched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baKMuwvv0QvH"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ed3aedafd9436dbbfeac85a43deaa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "with open('sae_lens/auth/hf.txt', 'r') as f:\n",
    "    hf_token = f.read().strip()\n",
    "\n",
    "model_id = \"google/gemma-2-2b\"\n",
    "model_name = \"gemma-2-2b\"\n",
    "\n",
    "torch.set_grad_enabled(False) # avoid blowing up mem\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir=MODEL_DIR,\n",
    "    token=hf_token,\n",
    "    device_map=device,\n",
    "    low_cpu_mem_usage=True,\n",
    "    attn_implementation=\"eager\"\n",
    ")\n",
    "\n",
    "tokenizer =  AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir=MODEL_DIR,\n",
    "    token=hf_token,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "VOCAB = sorted(tokenizer.vocab, key=tokenizer.vocab.get)\n",
    "\n",
    "layer_idx = 10\n",
    "\n",
    "from nnsight import NNsight\n",
    "nnsight_model = NNsight(hf_model)\n",
    "nnsight_tracer_kwargs = {'scan': True, 'validate': False, 'use_cache': False, 'output_attentions': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3552/3552 [00:44<00:00, 79.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "969696"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sae_lens.sae_bench.ravel.ravel_dataset_builder import RAVELEntityPromptData\n",
    "\n",
    "full_entity_dataset = RAVELEntityPromptData.from_files('city', 'sae_lens/sae_bench/ravel/data', tokenizer)\n",
    "len(full_entity_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prompts remaining: 1000\n",
      "Total #prompts=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:37<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 49.40%\n",
      "Number of prompts remaining: 494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sampled_entity_dataset = full_entity_dataset.downsample(1000)\n",
    "print(f\"Number of prompts remaining: {len(sampled_entity_dataset)}\")\n",
    "\n",
    "prompt_max_length = 48\n",
    "sampled_entity_dataset.generate_completions(nnsight_model, tokenizer, max_length=prompt_max_length+8, prompt_max_length=prompt_max_length)\n",
    "\n",
    "sampled_entity_dataset.evaluate_correctness()\n",
    "\n",
    "# Filter correct completions\n",
    "correct_data = sampled_entity_dataset.filter_correct()\n",
    "\n",
    "# Filter top entities and templates\n",
    "filtered_data = correct_data.filter_top_entities_and_templates(top_n_entities=400, top_n_templates_per_attribute=12)\n",
    "\n",
    "# Calculate average accuracy\n",
    "accuracy = sampled_entity_dataset.calculate_average_accuracy()\n",
    "print(f\"Average accuracy: {accuracy:.2%}\")\n",
    "print(f\"Number of prompts remaining: {len(correct_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total #prompts=914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:31<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 938 Wikipedia prompt templates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_data.add_wikipedia_prompts('city', 'sae_lens/sae_bench/ravel/data', tokenizer, nnsight_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1408"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt(text='[{\"city\": \"San Francisco\", \"continent\": \"North America\"}, {\"city\": \"Nevers\", \"continent\": \"', template='[{\"city\": \"San Francisco\", \"continent\": \"North America\"}, {\"city\": \"%s\", \"continent\": \"', attribute='Continent', entity='Nevers', context_split='train', entity_split='val', input_ids=tensor([     1,      1,      1,      1,      1,      2, 235309,   9766,   8918,\n",
      "          1192,    664,  10105,  12288,    824,    664,  88770,   1192,    664,\n",
      "         17870,   5783,  16406,  19946,   8918,   1192,    664,   4157,   1267,\n",
      "           824,    664,  88770,   1192,    664]), attention_mask=tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1]), completion='Europe\"}, {\"city\": \"New York', is_correct=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for prompt in correct_data.prompts.keys():\n",
    "#     print(sampled_entity_dataset.prompts[prompt])\n",
    "#     break\n",
    "\n",
    "# version of the above that returns a random prompt each time\n",
    "def get_random_prompt(data):\n",
    "    prompt = random.choice(list(data.prompts.keys()))\n",
    "    return data.prompts[prompt]\n",
    "\n",
    "print(get_random_prompt(correct_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7H31GM_-iGa"
   },
   "source": [
    "# Create a RAVEL Instance for TinyLLaMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model knowledge of all entity - attribute pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnniGh2I-jYw",
    "outputId": "7fd96496-9a88-43fa-e181-07e5ee21235f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#entities=3552, #prompt_templates=273\n",
      "total number of prompts 969696\n"
     ]
    }
   ],
   "source": [
    "# Generate a dataset of combinations of entities and attribute_specific_prompts\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "entity_type = 'city'\n",
    "\n",
    "attribute_prompts = json.load(open(os.path.join(DATA_DIR, 'base', f'ravel_{entity_type}_attribute_to_prompts.json')))\n",
    "prompt_splits = json.load(open(os.path.join(DATA_DIR, 'base', f'ravel_{entity_type}_prompt_to_split.json')))\n",
    "entity_attributes = json.load(open(os.path.join(DATA_DIR, 'base', f'ravel_{entity_type}_entity_attributes.json')))\n",
    "print(f'#entities={len(entity_attributes)}, #prompt_templates={sum(map(len, attribute_prompts.values()))}')\n",
    "\n",
    "# # For testing purposes\n",
    "# partial_entitiy_attributes = {}\n",
    "# for i, (e, a) in enumerate(entity_attributes.items()):\n",
    "#     partial_entitiy_attributes[e] = a\n",
    "#     if i == 10:\n",
    "#         break\n",
    "# entity_attributes = partial_entitiy_attributes\n",
    "\n",
    "prompts_to_meta_data = {t % x: {'entity': x, 'attr': a, 'template': t}\n",
    "               for x in entity_attributes\n",
    "               for a, ts in attribute_prompts.items()\n",
    "               for t in ts}\n",
    "print(f'total number of prompts {len(prompts_to_meta_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompts_to_meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def subsample_dict(original_dict, num_samples):\n",
    "    keys = random.sample(list(original_dict.keys()), num_samples)\n",
    "    print(keys)\n",
    "    return {k: original_dict[k] for k in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "def filter_attribute_prompts(\n",
    "        attribute_prompts: Dict[str, List[str]], \n",
    "        prompts_to_meta_data_subsample: Dict[str, Dict[str, str]]\n",
    "    ) -> Dict[str, List[str]]:\n",
    "    \"\"\" Filter out attribute prompts that are not in the subsample\n",
    "\n",
    "    Args:\n",
    "        attribute_prompts (dict): attribute to list of prompts\n",
    "        prompts_to_meta_data_subsample (dict): prompt to metadata\n",
    "\n",
    "    Returns:\n",
    "        dict: filtered attribute prompts\n",
    "    \"\"\"\n",
    "    filtered_attribute_prompts = {}\n",
    "    for attr in list(attribute_prompts.keys()):\n",
    "        filtered_attribute_prompts[attr] = [p for p in attribute_prompts[attr] if p in set([prompts_to_meta_data_subsample[k]['template'] for k in prompts_to_meta_data_subsample.keys()])]\n",
    "        # if attr not in set([v['attr'] for v in prompts_to_meta_data_subsample.values()]):\n",
    "        #     del attribute_prompts[attr]\n",
    "\n",
    "    return filtered_attribute_prompts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ACeQLEvlYevO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[{\"city\": \"Cape Town\", \"lat\": \"33.9\"}, {\"city\": \"Turbat\", \"lat\": \"', '[{\"city\": \"New York City\", \"lang\": \"English\"}, {\"city\": \"Kanoya\", \"lang\": \"', '[{\"city\": \"Bangkok\", \"continent\": \"Asia\"}, {\"city\": \"Sikasso\", \"continent\": \"', '[{\"city\": \"Cape Town\", \"lat\": \"33.9\"}, {\"city\": \"Wuchuan\", \"lat\": \"', '[{\"city\": \"Kuala Lumpur\", \"lat\": \"3.1\"}, {\"city\": \"Kogon\", \"lat\": \"', 'The longitude of Apolo is ', ' \"continent\": \"Asia\"}, {\"city\": \"Ferfer\", \"long\": \"', 'New York City: America/New_York. Maracaju:', '[{\"city\": \"New York City\", \"lat\": \"41\"}, {\"city\": \"Luxor\", \"lat\": \"', ' \"continent\": \"Asia\"}, {\"city\": \"Kerma\", \"lat\": \"', '[{\"city\": \"Zhob\", \"timezone\": \"', '[{\"city\": \"Kuala Lumpur\", \"long\": \"101.7\"}, {\"city\": \"Suceava\", \"long\": \"', '[{\"city\": \"New Delhi\", \"lat\": \"29\"}, {\"city\": \"Totness\", \"lat\": \"', ' she is living in Gulu, therefore her country of residence is', ' in Lota, people usually speak', 'Tokyo is a city in the continent of Asia. Ituni is a city in the continent of', ' \"continent\": \"North America\"}, {\"city\": \"Nanchong\", \"timezone\": \"', 'Time zone in Bangkok is Asia/Bangkok; Time zone in Wum is', ' she is living in Yiyang, therefore her country of residence is', 'If you live in Deming, your country of residence should be', '[{\"city\": \"Toronto\", \"lat\": \"43.7\"}, {\"city\": \"Manhattan\", \"lat\": \"', '[{\"city\": \"New York City\", \"timezone\": \"UTC-5\"}, {\"city\": \"Byumba\", \"timezone\": \"UTC', '[{\"city\": \"Kuala Lumpur\", \"long\": \"101.7\"}, {\"city\": \"George\", \"long\": \"', 'Hong Kong: Asia/Hong_Kong. Caazapa:', 'city: Sibenik, timezone: UTC', 'Sydney is a city in the continent of Oceania. Bend is a city in the continent of', 'city to country: Hong Kong is in China. Omchak is in', '[{\"city\": \"St. Petersburg\", \"lat\": \"60\"}, {\"city\": \"Tampa\", \"lat\": \"', 'Escanaba is a city located in the continent of', '[{\"city\": \"Mexico City\", \"continent\": \"North America\"}, {\"city\": \"Yoro\", \"continent\": \"', '[{\"city\": \"Rio de Janeiro\", \"long\": \"43.2\"}, {\"city\": \"Meizhou\", \"long\": \"', '[{\"city\": \"Kuala Lumpur\", \"long\": \"101.7\"}, {\"city\": \"Rize\", \"long\": \"', 'city: Teller, timezone:', 'Time zone in Sydney is Australia/Sydney; Time zone in Nogales is', 'city to country: Toronto is in Canada. Yazd is in', '[{\"city\": \"Toronto\", \"lat\": \"43.7\"}, {\"city\": \"Caluula\", \"lat\": \"', '[{\"city\": \"Beijing\", \"continent\": \"Asia\"}, {\"city\": \"Hamar\", \"continent\": \"', 'The latitude of Bergen is (', 'Sydney is a city in the continent of Oceania. Sanming is a city in the continent of', 'Sydney is a city in the continent of Oceania. Bambari is a city in the continent of', '[{\"city\": \"Hong Kong\", \"lat\": \"22.3\"}, {\"city\": \"Yala\", \"lat\": \"', 'People in New Delhi speak Hindi, English. People in Ulkan speak', 'city to country: Rio de Janeiro is in Brazil. Qom is in', '[{\"city\": \"Cape Town\", \"continent\": \"Africa\"}, {\"city\": \"Horlivka\", \"continent\": \"', '[{\"city\": \"Toronto\", \"lat\": \"43.7\"}, {\"city\": \"Loikaw\", \"lat\": \"', 'Mexico City is a city in the continent of North America. Moree is a city in the continent of', 'Rome: Europe/Rome. Bethal:', '[{\"city\": \"Beijing\", \"timezone\": \"UTC+08:00\"}, {\"city\": \"Ishim\", \"timezone\": \"UTC', 'People in Rio de Janeiro speak Portuguese. People in Kumo speak', 'SF has a longitude of 122.4194° W. Harstad has a longitude of ', '[{\"city\": \"Hong Kong\", \"lat\": \"22\"}, {\"city\": \"Obando\", \"lat\": \"', 'Time zone in Hong Kong is Asia/Hong_Kong; Time zone in Palmer is', 'Time zone in Buenos Aires is America/Argentina/Buenos_Aires; Time zone in Zacapa is', '[{\"city\": \"Kuala Lumpur\", \"lat\": \"3\"}, {\"city\": \"Crotone\", \"lat\": \"', 'Mexico City is a city in the continent of North America. Monasir is a city in the continent of', 'city: Louisville, country:', '[{\"city\": \"Beijing\", \"lat\": \"39.9\"}, {\"city\": \"Lamar\", \"lat\": \"', 'People in Hong Kong speak Chinese, English. People in Vera speak', ' \"lat\": \"37.7749° N\"}, {\"city\": \"Massawa\", \"long\": \"', '[{\"city\": \"New Delhi\", \"long\": \"77.2\"}, {\"city\": \"Flensburg\", \"long\": \"', 'Mexico City is a city in the continent of North America. Awka is a city in the continent of', '[{\"city\": \"New Delhi\", \"country\": \"India\"}, {\"city\": \"Tatui\", \"country\": \"', 'Mexico City: America/Mexico_City. Zhosaly:', '[{\"city\": \"Hong Kong\", \"long\": \"114.2\"}, {\"city\": \"Moatize\", \"long\": \"', '[{\"city\": \"Los Angeles\", \"continent\": \"North America\"}, {\"city\": \"Zaraza\", \"continent\": \"', '[{\"city\": \"New Delhi\", \"timezone\": \"UTC+05:30\"}, {\"city\": \"Alatyr\", \"timezone\": \"UTC', '[{\"city\": \"Belgorod\", \"continent\": \"', 'The latitude of Salatiga is (', ' \"country\": \"United Kingdom\"}, {\"city\": \"Tulsa\", \"timezone\": \"', 'Time zone in Rio de Janeiro is America/Sao_Paulo; Time zone in Kavache is', '[{\"city\": \"Buenos Aires\", \"country\": \"Argentina\"}, {\"city\": \"Rostock\", \"country\": \"', 'Toledo is a city located in the continent of', '[{\"country\": \"France\", \"language\": \"Franch\"}, {\"city\": \"Suileng\", \"continent\": \"', 'SF has a latitude of 37.7749° N. Pori has a latitude of ', 'People in Kuala Lumpur speak Malay. People in Orleans speak', '[{\"city\": \"Kuala Lumpur\", \"lat\": \"3.1\"}, {\"city\": \"Abadan\", \"lat\": \"', '[{\"city\": \"Beijing\", \"continent\": \"Asia\"}, {\"city\": \"Obuasi\", \"continent\": \"', 'The IANA time zone identifier for Magangue is', '[{\"city\": \"Paris\", \"long\": \"2.4\"}, {\"city\": \"Tongue\", \"long\": \"', '[{\"city\": \"New Delhi\", \"lat\": \"28.6\"}, {\"city\": \"Vichy\", \"lat\": \"', '[{\"city\": \"San Francisco\", \"long\": \"122.4\"}, {\"city\": \"Hualien\", \"long\": \"', 'Time zone in New York City is America/New_York; Time zone in Elkhart is', '[{\"city\": \"Rio de Janeiro\", \"timezone\": \"UTC-03:00\"}, {\"city\": \"Santander\", \"timezone\": \"UTC', '[{\"city\": \"Tokyo\", \"country\": \"Japan\"}, {\"city\": \"Hirosaki\", \"country\": \"', 'People in Toronto speak English. People in Rivas speak', '[{\"city\": \"Paris\", \"lat\": \"49\"}, {\"city\": \"Vinh\", \"lat\": \"', '[{\"city\": \"Kuala Lumpur\", \"timezone\": \"UTC+08:00\"}, {\"city\": \"Aydin\", \"timezone\": \"UTC', 'Toronto: America/Toronto. Colombo:', 'New Delhi is a city in the continent of Asia. Zemio is a city in the continent of', 'New York City: America/New_York. Mubi:', '[{\"city\": \"San Francisco\", \"long\": \"122.4\"}, {\"city\": \"Devonport\", \"long\": \"', '[{\"city\": \"Beijing\", \"long\": \"116.4\"}, {\"city\": \"Eastmain\", \"long\": \"', 'People in Cape Town speak Afrikaans, English, Xhosa. People in Tarija speak', '[{\"city\": \"Tokyo\", \"continent\": \"Asia\"}, {\"city\": \"Caico\", \"continent\": \"', '[{\"city\": \"Rome\", \"timezone\": \"UTC+1:00\"}, {\"city\": \"Taree\", \"timezone\": \"UTC', 'People in Beijing speak Chinese. People in Milan speak', 'People in Paris speak French. People in Larnaka speak', '[{\"city\": \"Bangkok\", \"lat\": \"13.8\"}, {\"city\": \"Bekasi\", \"lat\": \"', '[{\"city\": \"Toronto\", \"timezone\": \"UTC-05:00\"}, {\"city\": \"Barras\", \"timezone\": \"UTC', '[{\"city\": \"Sydney\", \"continent\": \"Oceania\"}, {\"city\": \"Heihe\", \"continent\": \"']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'generate_batched' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m     15\u001b[0m     prompt_max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m48\u001b[39m\n\u001b[0;32m---> 17\u001b[0m     prompt_to_output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_batched\u001b[49m(\n\u001b[1;32m     18\u001b[0m         hf_model,\n\u001b[1;32m     19\u001b[0m         tokenizer,\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28mlist\u001b[39m(prompts_to_meta_data_subsample),\n\u001b[1;32m     21\u001b[0m         prompt_max_length\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     22\u001b[0m         prompt_max_length\u001b[38;5;241m=\u001b[39mprompt_max_length,\n\u001b[1;32m     23\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m     24\u001b[0m     prompt_to_output \u001b[38;5;241m=\u001b[39m {k: v[\u001b[38;5;28mlen\u001b[39m(k):] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m prompt_to_output}\n\u001b[1;32m     26\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(prompt_to_output, \u001b[38;5;28mopen\u001b[39m(prompt_to_output_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m), ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_batched' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate outputs for all prompts (the correct attribute is expected in the output)\n",
    "\n",
    "skip_the_inference_step = False\n",
    "prompts_to_meta_data_subsample = subsample_dict(prompts_to_meta_data, 100)\n",
    "attribute_prompts_subsample = filter_attribute_prompts(attribute_prompts, prompts_to_meta_data_subsample)\n",
    "prompt_to_output_path = os.path.join(DATA_DIR, model_name, f'ravel_{model_name}_{entity_type}_prompt_to_output.json')\n",
    "\n",
    "if skip_the_inference_step:\n",
    "    # Can skip the inference step by downloading the pre-computed outputs:\n",
    "    # https://drive.google.com/drive/u/0/folders/1U4Js-NarJa-B_iQc5wr0OXV2G-5BDBsN\n",
    "    pass\n",
    "else: \n",
    "    \n",
    "\n",
    "    prompt_max_length = 48\n",
    "\n",
    "    prompt_to_output = generate_batched(\n",
    "        hf_model,\n",
    "        tokenizer,\n",
    "        list(prompts_to_meta_data_subsample),\n",
    "        prompt_max_length+8,\n",
    "        prompt_max_length=prompt_max_length,\n",
    "        batch_size=256)\n",
    "    prompt_to_output = {k: v[len(k):] for k, v in prompt_to_output}\n",
    "\n",
    "    json.dump(prompt_to_output, open(prompt_to_output_path, 'w'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3dIZpkeyOtu",
    "outputId": "921a9d95-f3d2-4ecc-d532-a1aaa151f964"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_to_output = json.load(open(prompt_to_output_path))\n",
    "len(prompt_to_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Hong Kong: Asia/Hong_Kong. Resistencia:\n",
      "Entity: Resistencia\n",
      "Attribute: Timezone\n",
      "Template: Hong Kong: Asia/Hong_Kong. %s:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in prompts_to_meta_data_subsample.items():\n",
    "    \n",
    "    print(f'Prompt: {key}')\n",
    "    print(f'Entity: {value[\"entity\"]}')\n",
    "    print(f'Attribute: {value[\"attr\"]}')\n",
    "    print(f'Template: {value[\"template\"]}')\n",
    "    print()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Hong Kong: Asia/Hong_Kong. Resistencia:\n",
      "Output:  1989. 1\n",
      "\n",
      "Prompt:  in Volos, people usually speak\n",
      "Output:  Greek.\n",
      "\n",
      "<h2>What is the best\n",
      "\n",
      "Prompt: [{\"city\": \"Mexico City\", \"lat\": \"19.4\"}, {\"city\": \"Redding\", \"lat\": \"\n",
      "Output: 40.0\"}, {\"city\":\n",
      "\n",
      "Prompt:  city to continent: New York City is in North America. Kanpur is in\n",
      "Output:  India.\n",
      "\n",
      "Q: What is the\n",
      "\n",
      "Prompt: city to country: San Francisco is in United States. Astana is in\n",
      "Output:  Kazakhstan.\n",
      "\n",
      "city to city: New\n",
      "\n",
      "Prompt: [{\"city\": \"Kuala Lumpur\", \"continent\": \"Asia\"}, {\"city\": \"Varna\", \"continent\": \"\n",
      "Output: Europe\"}, {\"city\": \"Kuala\n",
      "\n",
      "Prompt: St. Petersburg is a city in the continent of Europe. Zanesville is a city in the continent of\n",
      "Output:  North America.\n",
      "\n",
      "St. Petersburg is\n",
      "\n",
      "Prompt: Time zone in Mexico City is America/Mexico_City; Time zone in Bol is\n",
      "Output:  America/Mexico_City; Time zone\n",
      "\n",
      "Prompt: San Francisco is a city in the continent of North America. Wuyuan is a city in the continent of\n",
      "Output:  Asia.\n",
      "\n",
      "The city of San Francisco\n",
      "\n",
      "Prompt: [{\"city\": \"Rio de Janeiro\", \"long\": \"43.2\"}, {\"city\": \"Atkarsk\", \"long\": \"\n",
      "Output: 43.2\"}, {\"city\":\n",
      "\n",
      "Prompt: [{\"city\": \"Huelva\", \"lat\": \"\n",
      "Output: 37.15000\n",
      "\n",
      "Prompt: [{\"city\": \"San Francisco\", \"lat\": \"38\"}, {\"city\": \"Casper\", \"lat\": \"\n",
      "Output: 41\"}, {\"city\": \"San\n",
      "\n",
      "Prompt: [{\"city\": \"New Delhi\", \"continent\": \"Asia\"}, {\"city\": \"Sirsa\", \"continent\": \"\n",
      "Output: Asia\"}, {\"city\": \"New Delhi\n",
      "\n",
      "Prompt: Fria is a city located in the continent of\n",
      "Output:  Aethia. It is the capital\n",
      "\n",
      "Prompt: city to country: New York City is in United States. Okara is in\n",
      "Output:  Pakistan.\n",
      "\n",
      "city to city: New\n",
      "\n",
      "Prompt: [{\"city\": \"Salcedo\", \"continent\": \"\n",
      "Output: North America\", \"country\": \"Mexico\n",
      "\n",
      "Prompt: Tokyo is a city in the continent of Asia. Moradabad is a city in the continent of\n",
      "Output:  Asia.\n",
      "\n",
      "The distance between Tokyo and\n",
      "\n",
      "Prompt: Time Zone Currently Being Used in Kwinana is\n",
      "Output: :\n",
      "\n",
      "* <strong>Australia/Perth\n",
      "\n",
      "Prompt: [{\"city\": \"Kuala Lumpur\", \"lat\": \"3\"}, {\"city\": \"Haiya\", \"lat\": \"\n",
      "Output: 3\"}, {\"city\": \"Kuala\n",
      "\n",
      "Prompt: [{\"city\": \"Beijing\", \"lang\": \"Chinese\"}, {\"city\": \"Mityana\", \"lang\": \"\n",
      "Output: English\"}, {\"city\": \"Mity\n",
      "\n",
      "Prompt: [{\"city\": \"Toronto\", \"continent\": \"North America\"}, {\"city\": \"Yalta\", \"continent\": \"\n",
      "Output: Europe\"}, {\"city\": \"New York\n",
      "\n",
      "Prompt: city: Kirkwall, latitude: (\n",
      "Output: 59.55000\n",
      "\n",
      "Prompt: [{\"city\": \"Beijing\", \"lat\": \"40\"}, {\"city\": \"Upata\", \"lat\": \"\n",
      "Output: 40\"}, {\"city\": \"Beijing\n",
      "\n",
      "Prompt: St. Petersburg: Europe/Moscow. Zaraza:\n",
      "Output:  1917. 1\n",
      "\n",
      "Prompt: St. Petersburg is a city in the continent of Europe. Lugano is a city in the continent of\n",
      "Output:  Europe.\n",
      "\n",
      "St. Petersburg is a\n",
      "\n",
      "Prompt: [{\"city\": \"Beijing\", \"continent\": \"Asia\"}, {\"city\": \"Juba\", \"continent\": \"\n",
      "Output: Africa\"}, {\"city\": \"New York\n",
      "\n",
      "Prompt: city: Derbent, latitude: (\n",
      "Output: 42.00000\n",
      "\n",
      "Prompt: city: Puebla, UTC offset:\n",
      "Output:  -6, time zone: America/\n",
      "\n",
      "Prompt: [{\"city\": \"New Delhi\", \"lat\": \"29\"}, {\"city\": \"Beipiao\", \"lat\": \"\n",
      "Output: 40\"}, {\"city\": \"New\n",
      "\n",
      "Prompt: Toronto is a city in the continent of North America. Samarinda is a city in the continent of\n",
      "Output:  Asia.\n",
      "\n",
      "Toronto is the capital of\n",
      "\n",
      "Prompt: [{\"city\": \"Rome\", \"timezone\": \"UTC+02:00\"}, {\"city\": \"Barnaul\", \"timezone\": \"UTC\n",
      "Output: +07:00\"}, {\"\n",
      "\n",
      "Prompt: St. Petersburg: Europe/Moscow. Surin:\n",
      "Output:  1990. First edition\n",
      "\n",
      "Prompt: [{\"city\": \"Cape Town\", \"lang\": \"Afrikaans, English, Xhosa\"}, {\"city\": \"Osijek\", \"lang\": \"\n",
      "Output: Croatian\"}, {\"city\": \"D\n",
      "\n",
      "Prompt: [{\"city\": \"Toronto\", \"lat\": \"44\"}, {\"city\": \"Bekasi\", \"lat\": \"\n",
      "Output: 44\"}, {\"city\": \"Jakarta\n",
      "\n",
      "Prompt: Manizales is a city in the country of\n",
      "Output:  Colombia. It is the capital of the\n",
      "\n",
      "Prompt:  \"long\": \"122.4194° W\"}, {\"city\": \"Algiers\", \"lat\": \"\n",
      "Output: 36.4500°\n",
      "\n",
      "Prompt: city to country: New Delhi is in India. Uruara is in\n",
      "Output:  Brazil.\n",
      "\n",
      "city to city: New\n",
      "\n",
      "Prompt: [{\"city\": \"Rome\", \"lat\": \"42\"}, {\"city\": \"Pilibhit\", \"lat\": \"\n",
      "Output: 27\"}, {\"city\": \"B\n",
      "\n",
      "Prompt: [{\"city\": \"Rome\", \"lat\": \"41.9\"}, {\"city\": \"Nanaimo\", \"lat\": \"\n",
      "Output: 49.2\"}, {\"city\":\n",
      "\n",
      "Prompt: [{\"city\": \"Bangkok\", \"lang\": \"Thai\"}, {\"city\": \"Mardan\", \"lang\": \"\n",
      "Output: Urdu\"}, {\"city\": \"M\n",
      "\n",
      "Prompt: [{\"city\": \"Sydney\", \"country\": \"Australia\"}, {\"city\": \"Horta\", \"country\": \"\n",
      "Output: Portugal\"}, {\"city\": \"Sydney\",\n",
      "\n",
      "Prompt: city to country: New Delhi is in India. Sari is in\n",
      "Output:  India.\n",
      "\n",
      "city to city: New\n",
      "\n",
      "Prompt: Time zone in Los Angeles is America/Santiago; Time zone in Ticul is\n",
      "Output:  America/Mexico_City.\n",
      "\n",
      "The\n",
      "\n",
      "Prompt: People in Newark usually speak\n",
      "Output:  English, but there are also many people\n",
      "\n",
      "Prompt: Time zone in Kuala Lumpur is Asia/Kuala_Lumpur; Time zone in Benguela is\n",
      "Output:  Africa/Luanda; Time zone in\n",
      "\n",
      "Prompt: Yantai is in the continent of\n",
      "Output:  China, and it is a city with\n",
      "\n",
      "Prompt: [{\"city\": \"New York City\", \"lat\": \"40.7\"}, {\"city\": \"Mostar\", \"lat\": \"\n",
      "Output: 43.7\"}, {\"city\":\n",
      "\n",
      "Prompt: SF has a latitude of 37.7749° N. Duitama has a latitude of \n",
      "Output: 5° 37' 3\n",
      "\n",
      "Prompt:  \"country\": \"United Kingdom\"}, {\"city\": \"Alotau\", \"language\": \"\n",
      "Output: English\", \"country\": \"Papua\n",
      "\n",
      "Prompt: [{\"city\": \"Rome\", \"lat\": \"41.9\"}, {\"city\": \"Aqsay\", \"lat\": \"\n",
      "Output: 41.9\"}, {\"city\":\n",
      "\n",
      "Prompt: SF has a latitude of 37.7749° N. Sur has a latitude of \n",
      "Output: 37.7749°\n",
      "\n",
      "Prompt: [{\"city\": \"San Francisco\", \"lang\": \"English\"}, {\"city\": \"Bengbu\", \"lang\": \"\n",
      "Output: English\"}, {\"city\": \"San Francisco\n",
      "\n",
      "Prompt: The latitude of Togiak is (\n",
      "Output: a) $60^{\\circ}\n",
      "\n",
      "Prompt:  \"continent\": \"Asia\"}, {\"city\": \"Santander\", \"lat\": \"\n",
      "Output: 43.45\", \"lon\n",
      "\n",
      "Prompt: [{\"city\": \"San Francisco\", \"lang\": \"English\"}, {\"city\": \"Hancheng\", \"lang\": \"\n",
      "Output: Chinese\"}, {\"city\": \"San Francisco\n",
      "\n",
      "Prompt: [{\"city\": \"Buenos Aires\", \"lat\": \"34.6\"}, {\"city\": \"Bekiy\", \"lat\": \"\n",
      "Output: 45.6\"}, {\"city\":\n",
      "\n",
      "Prompt: city: Tianshui, continent:\n",
      "Output:  China, country: China, province:\n",
      "\n",
      "Prompt: Time zone in Kuala Lumpur is Asia/Kuala_Lumpur; Time zone in Narvik is\n",
      "Output:  Europe/Oslo; Time zone in Singapore\n",
      "\n",
      "Prompt: Time zone in Vilnius is\n",
      "Output:  UTC+2.\n",
      "\n",
      "The time zone\n",
      "\n",
      "Prompt: city: Karnal, continent:\n",
      "Output:  India, country: India, state:\n",
      "\n",
      "Prompt: St. Petersburg is a city in the continent of Europe. Roslavl is a city in the continent of\n",
      "Output:  Europe.\n",
      "\n",
      "The city of St.\n",
      "\n",
      "Prompt: city to country: San Francisco is in United States. Brooks is in\n",
      "Output:  United States.\n",
      "\n",
      "San Francisco is in\n",
      "\n",
      "Prompt: Time zone in New York City is America/New_York; Time zone in Solola is\n",
      "Output:  America/Guatemala; Time zone in San\n",
      "\n",
      "Prompt: [{\"city\": \"Sydney\", \"lat\": \"34\"}, {\"city\": \"Wuwei\", \"lat\": \"\n",
      "Output: 34\"}, {\"city\": \"Sydney\n",
      "\n",
      "Prompt:  \"long\": \"122.4\"}, {\"city\": \"Nacala\", \"long\": \"\n",
      "Output: 13.4\"}, {\"city\":\n",
      "\n",
      "Prompt: [{\"city\": \"Rio de Janeiro\", \"lat\": \"23\"}, {\"city\": \"Zorgo\", \"lat\": \"\n",
      "Output: 23\"}, {\"city\": \"Rio\n",
      "\n",
      "Prompt: [{\"city\": \"Buenos Aires\", \"continent\": \"South America\"}, {\"city\": \"Obidos\", \"continent\": \"\n",
      "Output: Europe\"}, {\"city\": \"New York\n",
      "\n",
      "Prompt: [{\"city\": \"Cape Town\", \"lat\": \"34\"}, {\"city\": \"Medford\", \"lat\": \"\n",
      "Output: 42\"}, {\"city\": \"San\n",
      "\n",
      "Prompt: New Delhi is a city in the continent of Asia. Vellore is a city in the continent of\n",
      "Output:  Asia.\n",
      "\n",
      "The city of New Delhi\n",
      "\n",
      "Prompt: People in Mexico City speak Spanish. People in Weihai speak\n",
      "Output:  Chinese. People in New York City speak\n",
      "\n",
      "Prompt: Toronto: America/Toronto. Coroata:\n",
      "Output:  1970. First Edition\n",
      "\n",
      "Prompt: [{\"city\": \"St. Petersburg\", \"lang\": \"Russian\"}, {\"city\": \"Gaspe\", \"lang\": \"\n",
      "Output: French\"}, {\"city\": \"St.\n",
      "\n",
      "Prompt: [{\"city\": \"New Delhi\", \"timezone\": \"UTC+5:30\"}, {\"city\": \"Granja\", \"timezone\": \"UTC\n",
      "Output: -3\"}, {\"city\": \"New\n",
      "\n",
      "Prompt:  \"continent\": \"North America\"}, {\"city\": \"Carupano\", \"timezone\": \"\n",
      "Output: America/Sao_Paulo\", \"continent\n",
      "\n",
      "Prompt: [{\"city\": \"San Francisco\", \"continent\": \"North America\"}, {\"city\": \"Yomou\", \"continent\": \"\n",
      "Output: Africa\"}, {\"city\": \"San Francisco\n",
      "\n",
      "Prompt: People in Buenos Aires speak Spanish. People in Chumphon speak\n",
      "Output:  Thai. People in New York speak English\n",
      "\n",
      "Prompt: People in Bangkok speak Thai. People in Natchez speak\n",
      "Output:  English.\n",
      "\n",
      "But the two cities have\n",
      "\n",
      "Prompt: city to country: Cape Town is in South Africa. Dillon is in\n",
      "Output:  the United States.\n",
      "\n",
      "city to city\n",
      "\n",
      "Prompt: Time zone in Mexico City is America/Mexico_City; Time zone in Busan is\n",
      "Output:  Asia/Seoul; Time zone in Seoul\n",
      "\n",
      "Prompt: [{\"city\": \"New Delhi\", \"lang\": \"Hindi, English\"}, {\"city\": \"Brusque\", \"lang\": \"\n",
      "Output: Portuguese\"}, {\"city\": \"New Delhi\n",
      "\n",
      "Prompt: [{\"city\": \"Hong Kong\", \"lat\": \"22.3\"}, {\"city\": \"Wabag\", \"lat\": \"\n",
      "Output: 10.3\"}, {\"city\":\n",
      "\n",
      "Prompt: [{\"city\": \"New Delhi\", \"timezone\": \"UTC+05:30\"}, {\"city\": \"Djenne\", \"timezone\": \"UTC\n",
      "Output: +01:00\"}, {\"\n",
      "\n",
      "Prompt: The longitude of Faro is \n",
      "Output: 8 degrees west of Greenwich.\n",
      "\n",
      "The\n",
      "\n",
      "Prompt: city to country: New Delhi is in India. Maitland is in\n",
      "Output:  Australia.\n",
      "\n",
      "city to city: New\n",
      "\n",
      "Prompt: [{\"city\": \"Bangkok\", \"long\": \"100.5\"}, {\"city\": \"Superior\", \"long\": \"\n",
      "Output: 100.5\"}, {\"city\n",
      "\n",
      "Prompt: [{\"city\": \"Hong Kong\", \"lang\": \"Chinese, English\"}, {\"city\": \"Gulu\", \"lang\": \"\n",
      "Output: English\"}, {\"city\": \"Gulu\n",
      "\n",
      "Prompt: [{\"city\": \"San Francisco\", \"timezone\": \"UTC-8\"}, {\"city\": \"Caldera\", \"timezone\": \"UTC\n",
      "Output: -8\"}, {\"city\": \"San\n",
      "\n",
      "Prompt: Time zone in Sydney is Australia/Sydney; Time zone in Sasebo is\n",
      "Output:  Japan/Tokyo.\n",
      "\n",
      "The time difference\n",
      "\n",
      "Prompt: Time zone in Hong Kong is Asia/Hong_Kong; Time zone in Olbia is\n",
      "Output:  Europe/Rome; Time zone in Hong\n",
      "\n",
      "Prompt: [{\"city\": \"Tokyo\", \"country\": \"Japan\"}, {\"city\": \"Gafsa\", \"country\": \"\n",
      "Output: Tunisia\"}, {\"city\": \"Tokyo\",\n",
      "\n",
      "Prompt: Rome is a city in the continent of Europe. Crotone is a city in the continent of\n",
      "Output:  Europe.\n",
      "\n",
      "Rome is the capital of\n",
      "\n",
      "Prompt: [{\"city\": \"Kuala Lumpur\", \"continent\": \"Asia\"}, {\"city\": \"Bareilly\", \"continent\": \"\n",
      "Output: Asia\"}, {\"city\": \"Kuala\n",
      "\n",
      "Prompt: [{\"city\": \"San Francisco\", \"lang\": \"English\"}, {\"city\": \"Bursa\", \"lang\": \"\n",
      "Output: Turkish\"}, {\"city\": \"San Francisco\n",
      "\n",
      "Prompt: [{\"city\": \"Sydney\", \"timezone\": \"UTC+10:00\"}, {\"city\": \"Yakima\", \"timezone\": \"UTC\n",
      "Output: -08:00\"}, {\"\n",
      "\n",
      "Prompt: [{\"city\": \"Bangkok\", \"long\": \"100.5\"}, {\"city\": \"Tupelo\", \"long\": \"\n",
      "Output: 33.8\"}, {\"city\":\n",
      "\n",
      "Prompt: Los Angeles: America/Los_Angeles. Pleven:\n",
      "Output:  Pleven, 1990\n",
      "\n",
      "Prompt: [{\"city\": \"Toronto\", \"country\": \"Canada\"}, {\"city\": \"Khorugh\", \"country\": \"\n",
      "Output: Iran\"}, {\"city\": \"Khor\n",
      "\n",
      "Prompt: [{\"city\": \"Buenos Aires\", \"country\": \"Argentina\"}, {\"city\": \"Chota\", \"country\": \"\n",
      "Output: Bolivia\"}, {\"city\": \"La Paz\n",
      "\n",
      "Prompt: Time zone in St. Petersburg is Europe/Moscow; Time zone in Corozal is\n",
      "Output:  America/Belize. The time difference between\n",
      "\n",
      "Prompt: city to country: Beijing is in China. Vinh is in\n",
      "Output:  Vietnam.\n",
      "\n",
      "city to city: Beijing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in prompt_to_output.items():\n",
    "    print(f'Prompt: {key}')\n",
    "    print(f'Output: {value}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "-haNRu475QT4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Entity: Resistencia\n",
      "Attribute: Timezone\n",
      "Prompt: Hong Kong: Asia/Hong_Kong. Resistencia:\n",
      "Label: america/argentina/cordoba Output: 1989. 1\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Volos\n",
      "Attribute: Language\n",
      "Prompt:  in Volos, people usually speak\n",
      "Label: greek Output: greek.\n",
      "\n",
      "<h2>what is the best\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Redding\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"Mexico City\", \"lat\": \"19.4\"}, {\"city\": \"Redding\", \"lat\": \"\n",
      "Label: 41 Output: 40.0\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Kanpur\n",
      "Attribute: Continent\n",
      "Prompt:  city to continent: New York City is in North America. Kanpur is in\n",
      "Label: asia Output: india.\n",
      "\n",
      "q: what is the\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Astana\n",
      "Attribute: Country\n",
      "Prompt: city to country: San Francisco is in United States. Astana is in\n",
      "Label: kazakhstan Output: kazakhstan.\n",
      "\n",
      "city to city: new\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Varna\n",
      "Attribute: Continent\n",
      "Prompt: [{\"city\": \"Kuala Lumpur\", \"continent\": \"Asia\"}, {\"city\": \"Varna\", \"continent\": \"\n",
      "Label: europe Output: europe\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Zanesville\n",
      "Attribute: Continent\n",
      "Prompt: St. Petersburg is a city in the continent of Europe. Zanesville is a city in the continent of\n",
      "Label: north america Output: north america.\n",
      "\n",
      "st. petersburg is\n",
      "Correct: True\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Bol\n",
      "Attribute: Timezone\n",
      "Prompt: Time zone in Mexico City is America/Mexico_City; Time zone in Bol is\n",
      "Label: africa/ndjamena Output: america/mexico_city; time zone\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Wuyuan\n",
      "Attribute: Continent\n",
      "Prompt: San Francisco is a city in the continent of North America. Wuyuan is a city in the continent of\n",
      "Label: asia Output: asia.\n",
      "\n",
      "the city of san francisco\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Atkarsk\n",
      "Attribute: Longitude\n",
      "Prompt: [{\"city\": \"Rio de Janeiro\", \"long\": \"43.2\"}, {\"city\": \"Atkarsk\", \"long\": \"\n",
      "Label: 45 Output: 43.2\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Huelva\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"Huelva\", \"lat\": \"\n",
      "Label: 37 Output: 37.15000\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Casper\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"San Francisco\", \"lat\": \"38\"}, {\"city\": \"Casper\", \"lat\": \"\n",
      "Label: 43 Output: 41\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Sirsa\n",
      "Attribute: Continent\n",
      "Prompt: [{\"city\": \"New Delhi\", \"continent\": \"Asia\"}, {\"city\": \"Sirsa\", \"continent\": \"\n",
      "Label: asia Output: asia\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Fria\n",
      "Attribute: Continent\n",
      "Prompt: Fria is a city located in the continent of\n",
      "Label: africa Output: aethia. it is the capital\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Okara\n",
      "Attribute: Country\n",
      "Prompt: city to country: New York City is in United States. Okara is in\n",
      "Label: pakistan Output: pakistan.\n",
      "\n",
      "city to city: new\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Salcedo\n",
      "Attribute: Continent\n",
      "Prompt: [{\"city\": \"Salcedo\", \"continent\": \"\n",
      "Label: north america Output: north america\n",
      "Correct: True\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Moradabad\n",
      "Attribute: Continent\n",
      "Prompt: Tokyo is a city in the continent of Asia. Moradabad is a city in the continent of\n",
      "Label: asia Output: asia.\n",
      "\n",
      "the distance between tokyo and\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Kwinana\n",
      "Attribute: Timezone\n",
      "Prompt: Time Zone Currently Being Used in Kwinana is\n",
      "Label: australia/perth Output: :\n",
      "\n",
      "* <strong>australia/perth\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Haiya\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"Kuala Lumpur\", \"lat\": \"3\"}, {\"city\": \"Haiya\", \"lat\": \"\n",
      "Label: 18 Output: 3\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Mityana\n",
      "Attribute: Language\n",
      "Prompt: [{\"city\": \"Beijing\", \"lang\": \"Chinese\"}, {\"city\": \"Mityana\", \"lang\": \"\n",
      "Label: english Output: english\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Yalta\n",
      "Attribute: Continent\n",
      "Prompt: [{\"city\": \"Toronto\", \"continent\": \"North America\"}, {\"city\": \"Yalta\", \"continent\": \"\n",
      "Label: europe Output: europe\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Kirkwall\n",
      "Attribute: Latitude\n",
      "Prompt: city: Kirkwall, latitude: (\n",
      "Label: 59 Output: 59.55000\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Upata\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"Beijing\", \"lat\": \"40\"}, {\"city\": \"Upata\", \"lat\": \"\n",
      "Label: 8 Output: 40\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Zaraza\n",
      "Attribute: Timezone\n",
      "Prompt: St. Petersburg: Europe/Moscow. Zaraza:\n",
      "Label: america/caracas Output: 1917. 1\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Lugano\n",
      "Attribute: Continent\n",
      "Prompt: St. Petersburg is a city in the continent of Europe. Lugano is a city in the continent of\n",
      "Label: europe Output: europe.\n",
      "\n",
      "st. petersburg is a\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Juba\n",
      "Attribute: Continent\n",
      "Prompt: [{\"city\": \"Beijing\", \"continent\": \"Asia\"}, {\"city\": \"Juba\", \"continent\": \"\n",
      "Label: africa Output: africa\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Derbent\n",
      "Attribute: Latitude\n",
      "Prompt: city: Derbent, latitude: (\n",
      "Label: 42 Output: 42.00000\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Puebla\n",
      "Attribute: Timezone\n",
      "Prompt: city: Puebla, UTC offset:\n",
      "Label: -6:00 Output: -6, time zone: america/\n",
      "Correct: True\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Beipiao\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"New Delhi\", \"lat\": \"29\"}, {\"city\": \"Beipiao\", \"lat\": \"\n",
      "Label: 42 Output: 40\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Samarinda\n",
      "Attribute: Continent\n",
      "Prompt: Toronto is a city in the continent of North America. Samarinda is a city in the continent of\n",
      "Label: asia Output: asia.\n",
      "\n",
      "toronto is the capital of\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Barnaul\n",
      "Attribute: Timezone\n",
      "Prompt: [{\"city\": \"Rome\", \"timezone\": \"UTC+02:00\"}, {\"city\": \"Barnaul\", \"timezone\": \"UTC\n",
      "Label: +7:00 Output: +07:00\n",
      "Correct: True\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Surin\n",
      "Attribute: Timezone\n",
      "Prompt: St. Petersburg: Europe/Moscow. Surin:\n",
      "Label: asia/bangkok Output: 1990. first edition\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Osijek\n",
      "Attribute: Language\n",
      "Prompt: [{\"city\": \"Cape Town\", \"lang\": \"Afrikaans, English, Xhosa\"}, {\"city\": \"Osijek\", \"lang\": \"\n",
      "Label: croatian Output: croatian\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Bekasi\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"Toronto\", \"lat\": \"44\"}, {\"city\": \"Bekasi\", \"lat\": \"\n",
      "Label: -6 Output: 44\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Manizales\n",
      "Attribute: Country\n",
      "Prompt: Manizales is a city in the country of\n",
      "Label: colombia Output: colombia. it is the capital of the\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Algiers\n",
      "Attribute: Latitude\n",
      "Prompt:  \"long\": \"122.4194° W\"}, {\"city\": \"Algiers\", \"lat\": \"\n",
      "Label: 37 Output: 36.4500°\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Uruara\n",
      "Attribute: Country\n",
      "Prompt: city to country: New Delhi is in India. Uruara is in\n",
      "Label: brazil Output: brazil.\n",
      "\n",
      "city to city: new\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Pilibhit\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"Rome\", \"lat\": \"42\"}, {\"city\": \"Pilibhit\", \"lat\": \"\n",
      "Label: 29 Output: 27\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Nanaimo\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"Rome\", \"lat\": \"41.9\"}, {\"city\": \"Nanaimo\", \"lat\": \"\n",
      "Label: 49 Output: 49.2\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Mardan\n",
      "Attribute: Language\n",
      "Prompt: [{\"city\": \"Bangkok\", \"lang\": \"Thai\"}, {\"city\": \"Mardan\", \"lang\": \"\n",
      "Label: english Output: urdu\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Horta\n",
      "Attribute: Country\n",
      "Prompt: [{\"city\": \"Sydney\", \"country\": \"Australia\"}, {\"city\": \"Horta\", \"country\": \"\n",
      "Label: portugal Output: portugal\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Sari\n",
      "Attribute: Country\n",
      "Prompt: city to country: New Delhi is in India. Sari is in\n",
      "Label: iran Output: india.\n",
      "\n",
      "city to city: new\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Ticul\n",
      "Attribute: Timezone\n",
      "Prompt: Time zone in Los Angeles is America/Santiago; Time zone in Ticul is\n",
      "Label: america/merida Output: america/mexico_city.\n",
      "\n",
      "the\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Newark\n",
      "Attribute: Language\n",
      "Prompt: People in Newark usually speak\n",
      "Label: english Output: english, but there are also many people\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Benguela\n",
      "Attribute: Timezone\n",
      "Prompt: Time zone in Kuala Lumpur is Asia/Kuala_Lumpur; Time zone in Benguela is\n",
      "Label: africa/luanda Output: africa/luanda; time zone in\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Yantai\n",
      "Attribute: Continent\n",
      "Prompt: Yantai is in the continent of\n",
      "Label: asia Output: china, and it is a city with\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Mostar\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"New York City\", \"lat\": \"40.7\"}, {\"city\": \"Mostar\", \"lat\": \"\n",
      "Label: 43 Output: 43.7\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Duitama\n",
      "Attribute: Latitude\n",
      "Prompt: SF has a latitude of 37.7749° N. Duitama has a latitude of \n",
      "Label: 6 Output: 5° 37' 3\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Alotau\n",
      "Attribute: Language\n",
      "Prompt:  \"country\": \"United Kingdom\"}, {\"city\": \"Alotau\", \"language\": \"\n",
      "Label: malenasian languages,papuan languages Output: english\n",
      "Correct: False\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Aqsay\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"Rome\", \"lat\": \"41.9\"}, {\"city\": \"Aqsay\", \"lat\": \"\n",
      "Label: 51 Output: 41.9\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Sur\n",
      "Attribute: Latitude\n",
      "Prompt: SF has a latitude of 37.7749° N. Sur has a latitude of \n",
      "Label: 23 Output: 37.7749°\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Bengbu\n",
      "Attribute: Language\n",
      "Prompt: [{\"city\": \"San Francisco\", \"lang\": \"English\"}, {\"city\": \"Bengbu\", \"lang\": \"\n",
      "Label: chinese Output: english\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Togiak\n",
      "Attribute: Latitude\n",
      "Prompt: The latitude of Togiak is (\n",
      "Label: 59 Output: a) $60^{\\circ}\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Santander\n",
      "Attribute: Latitude\n",
      "Prompt:  \"continent\": \"Asia\"}, {\"city\": \"Santander\", \"lat\": \"\n",
      "Label: 43 Output: 43.45\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Hancheng\n",
      "Attribute: Language\n",
      "Prompt: [{\"city\": \"San Francisco\", \"lang\": \"English\"}, {\"city\": \"Hancheng\", \"lang\": \"\n",
      "Label: chinese Output: chinese\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Bekiy\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"Buenos Aires\", \"lat\": \"34.6\"}, {\"city\": \"Bekiy\", \"lat\": \"\n",
      "Label: -24 Output: 45.6\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Tianshui\n",
      "Attribute: Continent\n",
      "Prompt: city: Tianshui, continent:\n",
      "Label: asia Output: china, country: china, province:\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Narvik\n",
      "Attribute: Timezone\n",
      "Prompt: Time zone in Kuala Lumpur is Asia/Kuala_Lumpur; Time zone in Narvik is\n",
      "Label: europe/oslo Output: europe/oslo; time zone in singapore\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Vilnius\n",
      "Attribute: Timezone\n",
      "Prompt: Time zone in Vilnius is\n",
      "Label: europe/vilnius Output: utc+2.\n",
      "\n",
      "the time zone\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Karnal\n",
      "Attribute: Continent\n",
      "Prompt: city: Karnal, continent:\n",
      "Label: asia Output: india, country: india, state:\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Roslavl\n",
      "Attribute: Continent\n",
      "Prompt: St. Petersburg is a city in the continent of Europe. Roslavl is a city in the continent of\n",
      "Label: europe Output: europe.\n",
      "\n",
      "the city of st.\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Brooks\n",
      "Attribute: Country\n",
      "Prompt: city to country: San Francisco is in United States. Brooks is in\n",
      "Label: canada Output: united states.\n",
      "\n",
      "san francisco is in\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Solola\n",
      "Attribute: Timezone\n",
      "Prompt: Time zone in New York City is America/New_York; Time zone in Solola is\n",
      "Label: america/guatemala Output: america/guatemala; time zone in san\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Wuwei\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"Sydney\", \"lat\": \"34\"}, {\"city\": \"Wuwei\", \"lat\": \"\n",
      "Label: 38 Output: 34\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Nacala\n",
      "Attribute: Longitude\n",
      "Prompt:  \"long\": \"122.4\"}, {\"city\": \"Nacala\", \"long\": \"\n",
      "Label: 41 Output: 13.4\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Zorgo\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"Rio de Janeiro\", \"lat\": \"23\"}, {\"city\": \"Zorgo\", \"lat\": \"\n",
      "Label: 12 Output: 23\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Obidos\n",
      "Attribute: Continent\n",
      "Prompt: [{\"city\": \"Buenos Aires\", \"continent\": \"South America\"}, {\"city\": \"Obidos\", \"continent\": \"\n",
      "Label: south america Output: europe\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Medford\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"Cape Town\", \"lat\": \"34\"}, {\"city\": \"Medford\", \"lat\": \"\n",
      "Label: 42 Output: 42\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Vellore\n",
      "Attribute: Continent\n",
      "Prompt: New Delhi is a city in the continent of Asia. Vellore is a city in the continent of\n",
      "Label: asia Output: asia.\n",
      "\n",
      "the city of new delhi\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Weihai\n",
      "Attribute: Language\n",
      "Prompt: People in Mexico City speak Spanish. People in Weihai speak\n",
      "Label: chinese Output: chinese. people in new york city speak\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Coroata\n",
      "Attribute: Timezone\n",
      "Prompt: Toronto: America/Toronto. Coroata:\n",
      "Label: america/fortaleza Output: 1970. first edition\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Gaspe\n",
      "Attribute: Language\n",
      "Prompt: [{\"city\": \"St. Petersburg\", \"lang\": \"Russian\"}, {\"city\": \"Gaspe\", \"lang\": \"\n",
      "Label: french Output: french\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Granja\n",
      "Attribute: Timezone\n",
      "Prompt: [{\"city\": \"New Delhi\", \"timezone\": \"UTC+5:30\"}, {\"city\": \"Granja\", \"timezone\": \"UTC\n",
      "Label: -3:00 Output: -3\n",
      "Correct: True\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Carupano\n",
      "Attribute: Timezone\n",
      "Prompt:  \"continent\": \"North America\"}, {\"city\": \"Carupano\", \"timezone\": \"\n",
      "Label: america/caracas Output: america/sao_paulo\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Yomou\n",
      "Attribute: Continent\n",
      "Prompt: [{\"city\": \"San Francisco\", \"continent\": \"North America\"}, {\"city\": \"Yomou\", \"continent\": \"\n",
      "Label: africa Output: africa\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Chumphon\n",
      "Attribute: Language\n",
      "Prompt: People in Buenos Aires speak Spanish. People in Chumphon speak\n",
      "Label: thai Output: thai. people in new york speak english\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Natchez\n",
      "Attribute: Language\n",
      "Prompt: People in Bangkok speak Thai. People in Natchez speak\n",
      "Label: english Output: english.\n",
      "\n",
      "but the two cities have\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Dillon\n",
      "Attribute: Country\n",
      "Prompt: city to country: Cape Town is in South Africa. Dillon is in\n",
      "Label: United States Output: \n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Busan\n",
      "Attribute: Timezone\n",
      "Prompt: Time zone in Mexico City is America/Mexico_City; Time zone in Busan is\n",
      "Label: asia/seoul Output: asia/seoul; time zone in seoul\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Brusque\n",
      "Attribute: Language\n",
      "Prompt: [{\"city\": \"New Delhi\", \"lang\": \"Hindi, English\"}, {\"city\": \"Brusque\", \"lang\": \"\n",
      "Label: portuguese Output: portuguese\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Wabag\n",
      "Attribute: Latitude\n",
      "Prompt: [{\"city\": \"Hong Kong\", \"lat\": \"22.3\"}, {\"city\": \"Wabag\", \"lat\": \"\n",
      "Label: -5 Output: 10.3\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Djenne\n",
      "Attribute: Timezone\n",
      "Prompt: [{\"city\": \"New Delhi\", \"timezone\": \"UTC+05:30\"}, {\"city\": \"Djenne\", \"timezone\": \"UTC\n",
      "Label: +0:00 Output: +01:00\n",
      "Correct: True\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Faro\n",
      "Attribute: Longitude\n",
      "Prompt: The longitude of Faro is \n",
      "Label: -8 Output: 8 degrees west of greenwich.\n",
      "\n",
      "the\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Maitland\n",
      "Attribute: Country\n",
      "Prompt: city to country: New Delhi is in India. Maitland is in\n",
      "Label: australia Output: australia.\n",
      "\n",
      "city to city: new\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Superior\n",
      "Attribute: Longitude\n",
      "Prompt: [{\"city\": \"Bangkok\", \"long\": \"100.5\"}, {\"city\": \"Superior\", \"long\": \"\n",
      "Label: -92 Output: 100.5\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Gulu\n",
      "Attribute: Language\n",
      "Prompt: [{\"city\": \"Hong Kong\", \"lang\": \"Chinese, English\"}, {\"city\": \"Gulu\", \"lang\": \"\n",
      "Label: english Output: english\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Caldera\n",
      "Attribute: Timezone\n",
      "Prompt: [{\"city\": \"San Francisco\", \"timezone\": \"UTC-8\"}, {\"city\": \"Caldera\", \"timezone\": \"UTC\n",
      "Label: -3:00 Output: -8\n",
      "Correct: False\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Sasebo\n",
      "Attribute: Timezone\n",
      "Prompt: Time zone in Sydney is Australia/Sydney; Time zone in Sasebo is\n",
      "Label: asia/tokyo Output: japan/tokyo.\n",
      "\n",
      "the time difference\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Olbia\n",
      "Attribute: Timezone\n",
      "Prompt: Time zone in Hong Kong is Asia/Hong_Kong; Time zone in Olbia is\n",
      "Label: europe/rome Output: europe/rome; time zone in hong\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Gafsa\n",
      "Attribute: Country\n",
      "Prompt: [{\"city\": \"Tokyo\", \"country\": \"Japan\"}, {\"city\": \"Gafsa\", \"country\": \"\n",
      "Label: tunisia Output: tunisia\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Crotone\n",
      "Attribute: Continent\n",
      "Prompt: Rome is a city in the continent of Europe. Crotone is a city in the continent of\n",
      "Label: europe Output: europe.\n",
      "\n",
      "rome is the capital of\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Bareilly\n",
      "Attribute: Continent\n",
      "Prompt: [{\"city\": \"Kuala Lumpur\", \"continent\": \"Asia\"}, {\"city\": \"Bareilly\", \"continent\": \"\n",
      "Label: asia Output: asia\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Bursa\n",
      "Attribute: Language\n",
      "Prompt: [{\"city\": \"San Francisco\", \"lang\": \"English\"}, {\"city\": \"Bursa\", \"lang\": \"\n",
      "Label: arabic,kurdish,turkish Output: turkish\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Yakima\n",
      "Attribute: Timezone\n",
      "Prompt: [{\"city\": \"Sydney\", \"timezone\": \"UTC+10:00\"}, {\"city\": \"Yakima\", \"timezone\": \"UTC\n",
      "Label: -7:00 Output: -08:00\n",
      "Correct: True\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Tupelo\n",
      "Attribute: Longitude\n",
      "Prompt: [{\"city\": \"Bangkok\", \"long\": \"100.5\"}, {\"city\": \"Tupelo\", \"long\": \"\n",
      "Label: -89 Output: 33.8\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Pleven\n",
      "Attribute: Timezone\n",
      "Prompt: Los Angeles: America/Los_Angeles. Pleven:\n",
      "Label: europe/sofia Output: pleven, 1990\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Khorugh\n",
      "Attribute: Country\n",
      "Prompt: [{\"city\": \"Toronto\", \"country\": \"Canada\"}, {\"city\": \"Khorugh\", \"country\": \"\n",
      "Label: tajikistan Output: iran\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Chota\n",
      "Attribute: Country\n",
      "Prompt: [{\"city\": \"Buenos Aires\", \"country\": \"Argentina\"}, {\"city\": \"Chota\", \"country\": \"\n",
      "Label: peru Output: bolivia\n",
      "Correct: 0\n",
      "Updated stats: 0.0\n",
      "\n",
      "\n",
      "Entity: Corozal\n",
      "Attribute: Timezone\n",
      "Prompt: Time zone in St. Petersburg is Europe/Moscow; Time zone in Corozal is\n",
      "Label: america/belize Output: america/belize. the time difference between\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "\n",
      "\n",
      "Entity: Vinh\n",
      "Attribute: Country\n",
      "Prompt: city to country: Beijing is in China. Vinh is in\n",
      "Label: vietnam Output: vietnam.\n",
      "\n",
      "city to city: beijing\n",
      "Correct: 1\n",
      "Updated stats: 1.0\n",
      "Attribute: Country\n",
      "Attribute: Continent\n",
      "Attribute: Latitude\n",
      "Attribute: Longitude\n",
      "Attribute: Language\n",
      "Attribute: Timezone\n",
      "Kept 100 entity, 62 prompt template\n",
      "Average accuracy: 1.00%\n"
     ]
    }
   ],
   "source": [
    "#@title Behavioral Test\n",
    "\n",
    "## Check whether model output matches the correct attribute\n",
    "# Keep top 400 entities with highest sum of known attributes across all prompts\n",
    "# Keep top 12 templates per attribute\n",
    "\n",
    "import collections\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from zoneinfo import ZoneInfo\n",
    "import datetime\n",
    "\n",
    "def timezone_name_to_utc_offset(name):\n",
    "  offset =  ZoneInfo(name).utcoffset(datetime.datetime.now()).seconds\n",
    "  sign = '+'\n",
    "  if offset // 3600 >= 12:\n",
    "    offset = 24 * 3600 - offset\n",
    "    sign = '-'\n",
    "  fmt_offset = str(datetime.timedelta(seconds=offset)).rsplit(':', 1)[0]\n",
    "  if fmt_offset.startswith('0') and offset >= 1800:\n",
    "    fmt_offset = fmt_offset[1:]\n",
    "  return f'{sign}{fmt_offset}'\n",
    "\n",
    "\n",
    "# TODO: Pull out attribute checking to functions\n",
    "\n",
    "sorted_entity = sorted(set([v['entity'] for v in prompts_to_meta_data_subsample.values()]))\n",
    "sorted_template = sorted(set([v['template'] for v in prompts_to_meta_data_subsample.values()]))\n",
    "stats = np.zeros([len(sorted_entity), len(sorted_template)])\n",
    "for p, out in prompt_to_output.items():\n",
    "  attr = prompts_to_meta_data_subsample[p]['attr']\n",
    "  entity = prompts_to_meta_data_subsample[p]['entity']\n",
    "  label = entity_attributes[entity][attr]\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(f'Entity: {entity}')\n",
    "  print(f'Attribute: {attr}')\n",
    "  print(f'Prompt: {p}')\n",
    "  if not label:\n",
    "    print(f'No label for {entity} {attr}')\n",
    "    continue\n",
    "  norm_label = label.lower()\n",
    "  norm_out = out.split('\"')[0].strip(' \"').replace('\\\\/', '/').lower()\n",
    "\n",
    "  if len(norm_label) < len(norm_out):\n",
    "    correct = int(norm_out.startswith(norm_label))\n",
    "  else:\n",
    "    correct = int(norm_label.startswith(norm_out))\n",
    "\n",
    "\n",
    "\n",
    "  # Exceptions\n",
    "  if re.search('coord|\"lat\"|\"long\"|latitude|coordinates|longitude', p):\n",
    "    try:\n",
    "      correct = int((float(norm_label.strip('-−')) - float(re.findall(r'\\d+', norm_out)[0])) <= 2)\n",
    "    except:\n",
    "      correct = 0\n",
    "  if re.search('United States|United Kingdom', label):\n",
    "    norm_label = label.strip().replace('the ', '')\n",
    "    norm_out = out[len(p):].strip().replace('the ', '')\n",
    "    correct = int(norm_out.startswith(norm_label) or norm_out.startswith('England'))\n",
    "  if re.search('South Korea', label):\n",
    "    correct = int(norm_out.startswith('korea') or norm_out.startswith('south korea'))\n",
    "  if re.search('North America', label):\n",
    "    correct = norm_label in norm_out or norm_out == 'na' or norm_out.startswith('america')\n",
    "  if re.search('Mandarin', label):\n",
    "    correct = norm_out in norm_label or norm_out == 'chinese'\n",
    "  if re.search('language', p) and ',' in norm_label:\n",
    "    correct = any(lang in norm_out for lang in norm_label.split(','))\n",
    "  if re.search('UTC', p) and '/' in norm_label:\n",
    "    norm_label = timezone_name_to_utc_offset(label)\n",
    "    correct = norm_out.startswith(norm_label.split(':')[0])\n",
    "    if not correct and re.search(r'[+\\-]0\\d', norm_out):\n",
    "      correct = norm_out.replace('0', '', 1).startswith(norm_label.split(':')[0])\n",
    "    # Summer daylight saving time\n",
    "    if not correct and (\n",
    "        re.search(r'\\-[5-8]', norm_label) and label.startswith('America') or\n",
    "        re.search(r'\\+[0-3]', norm_label) and label.startswith('Europe') or\n",
    "        re.search(r'\\+[0-3]', norm_label) and label.startswith('Africa')):\n",
    "      #print('SUMMER TIME:', norm_label, norm_out)\n",
    "      out_offset_match = re.search(r'[+\\-]?(\\d\\d?):\\d+', norm_out)\n",
    "      label_offset_match = re.search(r'[+\\-]?(\\d\\d?):\\d+', norm_label)\n",
    "      if out_offset_match and label_offset_match:\n",
    "        norm_out_offset = int(out_offset_match.group(1))\n",
    "        norm_label_offset = int(label_offset_match.group(1))\n",
    "        correct = (norm_out_offset <= norm_label_offset + 1 and\n",
    "                    norm_out_offset >= norm_label_offset - 1)\n",
    "    if not correct and re.search(r'[+\\-](\\d+)', norm_out) and int(\n",
    "        re.search(r'[+\\-](\\d+)', norm_out).group(1)) > 11:\n",
    "      offset = 24 - int(re.search(r'[+\\-](\\d+)', norm_out).group(1))\n",
    "      correct = str(offset) in norm_label\n",
    "\n",
    "  print(f\"Label: {norm_label} Output: {norm_out}\")\n",
    "  print(f\"Correct: {correct}\")\n",
    "  stats[sorted_entity.index(prompts_to_meta_data_subsample[p]['entity']), sorted_template.index(prompts_to_meta_data_subsample[p]['template'])] += int(correct)\n",
    "  print(f\"Updated stats: {stats[sorted_entity.index(prompts_to_meta_data_subsample[p]['entity']), sorted_template.index(prompts_to_meta_data_subsample[p]['template'])]}\")\n",
    "# print('-----------------------------------')\n",
    "# for i in np.argsort(stats.sum(axis=0))[::-1]:\n",
    "#   print(sorted_template[i], int(stats[:, i].sum()), len(stats[:, i]))\n",
    "# for i in np.argsort(stats.sum(axis=-1))[::-1]:\n",
    "#   print(sorted_entity[i], int(stats[i].sum()), len(stats[i]))\n",
    "\n",
    "\n",
    "kept_entity_index = np.argsort(stats.sum(axis=1))\n",
    "KEPT_ENTITY = [sorted_entity[i] for i in kept_entity_index]\n",
    "topk_template_index = set(np.argsort(stats.sum(axis=0)))\n",
    "kept_template_index = []\n",
    "# A dict of all kept attribute to prompts.\n",
    "KEPT_ATTR_TO_PROMPT_AND_SPLIT = {}\n",
    "for attr in attribute_prompts_subsample:\n",
    "  # Kept the top 4 to 12 templates per attribute.\n",
    "  print(f'Attribute: {attr}')\n",
    "  attr_indices = [sorted_template.index(t) for t in attribute_prompts_subsample[attr]]\n",
    "  per_attr_kept_template_index = sorted(attr_indices, key=lambda i: stats[:, i].sum())[-12:][::-1]\n",
    "  per_attr_kept_template_index = [x for i, x in enumerate(per_attr_kept_template_index)\n",
    "                                  if x in topk_template_index or i < 4]\n",
    "  kept_template_index.extend(per_attr_kept_template_index)\n",
    "  KEPT_ATTR_TO_PROMPT_AND_SPLIT[attr] = {sorted_template[i]: prompt_splits[sorted_template[i]]\n",
    "                               for i in per_attr_kept_template_index}\n",
    "print('Kept %d entity, %d prompt template' % (len(kept_entity_index), len(kept_template_index)))\n",
    "\n",
    "print('Average accuracy: %.2f%%' % (100 *  (stats[:, kept_template_index][kept_entity_index, :]).sum()/ (len(kept_entity_index) * len(kept_template_index))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkJzIW0cNDSt",
    "outputId": "8aa5c498-6f1a-491c-dfa7-3943e62b03f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\tcity to country: New Delhi is in India. %s is in\t0.02\n",
      "test\tcity to country: San Francisco is in United States. %s is in\t0.01\n",
      "val\tcity to country: New York City is in United States. %s is in\t0.01\n",
      "val\tcity to country: Beijing is in China. %s is in\t0.01\n",
      "train\t[{\"city\": \"Tokyo\", \"country\": \"Japan\"}, {\"city\": \"%s\", \"country\": \"\t0.01\n",
      "test\t[{\"city\": \"Sydney\", \"country\": \"Australia\"}, {\"city\": \"%s\", \"country\": \"\t0.01\n",
      "test\t%s is a city in the country of\t0.01\n",
      "train\tcity to country: Cape Town is in South Africa. %s is in\t0.00\n",
      "train\t[{\"city\": \"Toronto\", \"country\": \"Canada\"}, {\"city\": \"%s\", \"country\": \"\t0.00\n",
      "train\t[{\"city\": \"Buenos Aires\", \"country\": \"Argentina\"}, {\"city\": \"%s\", \"country\": \"\t0.00\n",
      "train\tSt. Petersburg is a city in the continent of Europe. %s is a city in the continent of\t0.03\n",
      "val\t[{\"city\": \"Kuala Lumpur\", \"continent\": \"Asia\"}, {\"city\": \"%s\", \"continent\": \"\t0.02\n",
      "train\t[{\"city\": \"Toronto\", \"continent\": \"North America\"}, {\"city\": \"%s\", \"continent\": \"\t0.01\n",
      "train\t[{\"city\": \"San Francisco\", \"continent\": \"North America\"}, {\"city\": \"%s\", \"continent\": \"\t0.01\n",
      "test\t[{\"city\": \"New Delhi\", \"continent\": \"Asia\"}, {\"city\": \"%s\", \"continent\": \"\t0.01\n",
      "train\t[{\"city\": \"Beijing\", \"continent\": \"Asia\"}, {\"city\": \"%s\", \"continent\": \"\t0.01\n",
      "train\t[{\"city\": \"%s\", \"continent\": \"\t0.01\n",
      "train\tToronto is a city in the continent of North America. %s is a city in the continent of\t0.01\n",
      "train\tTokyo is a city in the continent of Asia. %s is a city in the continent of\t0.01\n",
      "val\tSan Francisco is a city in the continent of North America. %s is a city in the continent of\t0.01\n",
      "test\tRome is a city in the continent of Europe. %s is a city in the continent of\t0.01\n",
      "train\tNew Delhi is a city in the continent of Asia. %s is a city in the continent of\t0.01\n",
      "test\tcity: %s, latitude: (\t0.02\n",
      "val\tSF has a latitude of 37.7749° N. %s has a latitude of \t0.02\n",
      "train\t[{\"city\": \"Toronto\", \"lat\": \"44\"}, {\"city\": \"%s\", \"lat\": \"\t0.01\n",
      "train\t[{\"city\": \"San Francisco\", \"lat\": \"38\"}, {\"city\": \"%s\", \"lat\": \"\t0.01\n",
      "train\t[{\"city\": \"Rome\", \"lat\": \"42\"}, {\"city\": \"%s\", \"lat\": \"\t0.01\n",
      "train\t[{\"city\": \"Rome\", \"lat\": \"41.9\"}, {\"city\": \"%s\", \"lat\": \"\t0.01\n",
      "train\t[{\"city\": \"Rio de Janeiro\", \"lat\": \"23\"}, {\"city\": \"%s\", \"lat\": \"\t0.01\n",
      "train\t[{\"city\": \"New York City\", \"lat\": \"40.7\"}, {\"city\": \"%s\", \"lat\": \"\t0.01\n",
      "train\t[{\"city\": \"New Delhi\", \"lat\": \"29\"}, {\"city\": \"%s\", \"lat\": \"\t0.01\n",
      "test\t[{\"city\": \"Mexico City\", \"lat\": \"19.4\"}, {\"city\": \"%s\", \"lat\": \"\t0.01\n",
      "train\t[{\"city\": \"Hong Kong\", \"lat\": \"22.3\"}, {\"city\": \"%s\", \"lat\": \"\t0.01\n",
      "val\t[{\"city\": \"Cape Town\", \"lat\": \"34\"}, {\"city\": \"%s\", \"lat\": \"\t0.01\n",
      "train\t[{\"city\": \"Rio de Janeiro\", \"long\": \"43.2\"}, {\"city\": \"%s\", \"long\": \"\t0.01\n",
      "train\t[{\"city\": \"Bangkok\", \"long\": \"100.5\"}, {\"city\": \"%s\", \"long\": \"\t0.01\n",
      "val\tThe longitude of %s is \t0.01\n",
      "train\t \"long\": \"122.4\"}, {\"city\": \"%s\", \"long\": \"\t0.00\n",
      "val\t[{\"city\": \"St. Petersburg\", \"lang\": \"Russian\"}, {\"city\": \"%s\", \"lang\": \"\t0.01\n",
      "train\t[{\"city\": \"San Francisco\", \"lang\": \"English\"}, {\"city\": \"%s\", \"lang\": \"\t0.01\n",
      "val\t[{\"city\": \"New Delhi\", \"lang\": \"Hindi, English\"}, {\"city\": \"%s\", \"lang\": \"\t0.01\n",
      "train\t[{\"city\": \"Hong Kong\", \"lang\": \"Chinese, English\"}, {\"city\": \"%s\", \"lang\": \"\t0.01\n",
      "test\t[{\"city\": \"Cape Town\", \"lang\": \"Afrikaans, English, Xhosa\"}, {\"city\": \"%s\", \"lang\": \"\t0.01\n",
      "train\t[{\"city\": \"Beijing\", \"lang\": \"Chinese\"}, {\"city\": \"%s\", \"lang\": \"\t0.01\n",
      "train\tPeople in Mexico City speak Spanish. People in %s speak\t0.01\n",
      "val\tPeople in Buenos Aires speak Spanish. People in %s speak\t0.01\n",
      "val\tPeople in Bangkok speak Thai. People in %s speak\t0.01\n",
      "train\tPeople in %s usually speak\t0.01\n",
      "train\t in %s, people usually speak\t0.01\n",
      "test\t[{\"city\": \"Bangkok\", \"lang\": \"Thai\"}, {\"city\": \"%s\", \"lang\": \"\t0.00\n",
      "val\tTime zone in Kuala Lumpur is Asia/Kuala_Lumpur; Time zone in %s is\t0.02\n",
      "test\tcity: %s, UTC offset:\t0.01\n",
      "train\t[{\"city\": \"Sydney\", \"timezone\": \"UTC+10:00\"}, {\"city\": \"%s\", \"timezone\": \"UTC\t0.01\n",
      "val\t[{\"city\": \"Rome\", \"timezone\": \"UTC+02:00\"}, {\"city\": \"%s\", \"timezone\": \"UTC\t0.01\n",
      "train\t[{\"city\": \"New Delhi\", \"timezone\": \"UTC+5:30\"}, {\"city\": \"%s\", \"timezone\": \"UTC\t0.01\n",
      "val\t[{\"city\": \"New Delhi\", \"timezone\": \"UTC+05:30\"}, {\"city\": \"%s\", \"timezone\": \"UTC\t0.01\n",
      "val\tTime zone in St. Petersburg is Europe/Moscow; Time zone in %s is\t0.01\n",
      "train\tTime zone in New York City is America/New_York; Time zone in %s is\t0.01\n",
      "train\tTime zone in Mexico City is America/Mexico_City; Time zone in %s is\t0.01\n",
      "train\tTime zone in Hong Kong is Asia/Hong_Kong; Time zone in %s is\t0.01\n",
      "test\t[{\"city\": \"San Francisco\", \"timezone\": \"UTC-8\"}, {\"city\": \"%s\", \"timezone\": \"UTC\t0.00\n",
      "train\tToronto: America/Toronto. %s:\t0.00\n"
     ]
    }
   ],
   "source": [
    "# Print top 12 templates for each attribute\n",
    "\n",
    "attribute_prompts\n",
    "for i in kept_template_index:\n",
    "  print(f'{prompt_splits[sorted_template[i]]}\\t{sorted_template[i]}\\t{stats[:, i][kept_entity_index].mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngPJHQoOLH3b",
    "outputId": "422add7a-bc51-43b0-9bb5-60832c58583f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "Country Counter({'train': 4, 'val': 3, 'test': 3})\n",
      "Continent Counter({'train': 8, 'val': 2, 'test': 2})\n",
      "Latitude Counter({'train': 8, 'test': 2, 'val': 2})\n",
      "Longitude Counter({'train': 3, 'val': 1})\n",
      "Language Counter({'train': 6, 'val': 4, 'test': 2})\n",
      "Timezone Counter({'train': 6, 'val': 4, 'test': 2})\n"
     ]
    }
   ],
   "source": [
    "# train/val/test split of attribute_specific_prompt_templates has been predefined. Check whether the split is roughly balanced.\n",
    "\n",
    "print(sum(map(len, KEPT_ATTR_TO_PROMPT_AND_SPLIT.values())))\n",
    "for attr, prompt_to_split in KEPT_ATTR_TO_PROMPT_AND_SPLIT.items():\n",
    "  print(attr, collections.Counter(prompt_to_split.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoswMLAT8Fk7"
   },
   "source": [
    "### Create an Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "az5kBoagLBDU",
    "outputId": "ea8becbe-157b-4758-e105-ace0995ec28a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'KEPT_ENTITY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m WIKI_PROMPT_SPLITS \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwikipedia_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mENTITY_TYPE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_entity_prompts.json\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Filtered\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m KEPT_ENTITY_SPLITS \u001b[38;5;241m=\u001b[39m {e: ALL_ENTITY_SPLITS[e] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[43mKEPT_ENTITY\u001b[49m} \u001b[38;5;66;03m# kept entities to split\u001b[39;00m\n\u001b[1;32m     12\u001b[0m KEPT_PROMPT_SPLITS \u001b[38;5;241m=\u001b[39m {k: (a, v) \u001b[38;5;28;01mfor\u001b[39;00m a, d \u001b[38;5;129;01min\u001b[39;00m KEPT_ATTR_TO_PROMPT_AND_SPLIT\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m}\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlen kept prompt splits=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(KEPT_PROMPT_SPLITS)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KEPT_ENTITY' is not defined"
     ]
    }
   ],
   "source": [
    "# train/val/test split of entities has been predefined. Check whether the split is roughly balanced.\n",
    "import json\n",
    "\n",
    "ENTITY_TYPE = 'city'\n",
    "print(ENTITY_TYPE)\n",
    "ALL_ENTITY_SPLITS = json.load(open(os.path.join(DATA_DIR, 'base', f'ravel_{ENTITY_TYPE}_entity_to_split.json')))\n",
    "ALL_ATTR_TO_PROMPTS = json.load(open(os.path.join(DATA_DIR, 'base', f'ravel_{ENTITY_TYPE}_attribute_to_prompts.json')))\n",
    "WIKI_PROMPT_SPLITS = json.load(open(os.path.join(DATA_DIR, 'base', f'wikipedia_{ENTITY_TYPE}_entity_prompts.json')))\n",
    "\n",
    "# Filtered\n",
    "KEPT_ENTITY_SPLITS = {e: ALL_ENTITY_SPLITS[e] for e in KEPT_ENTITY} # kept entities to split\n",
    "KEPT_PROMPT_SPLITS = {k: (a, v) for a, d in KEPT_ATTR_TO_PROMPT_AND_SPLIT.items() for k, v in d.items() if k.count('%') == 1}\n",
    "print(f'len kept prompt splits={len(KEPT_PROMPT_SPLITS)}')\n",
    "print(f'len added wiki inv prompts={len({k: v for k, v in WIKI_PROMPT_SPLITS.items() if k.count(\"%\") == 1})}')\n",
    "for prompt in WIKI_PROMPT_SPLITS:\n",
    "  KEPT_PROMPT_SPLITS[prompt] = ('Other', WIKI_PROMPT_SPLITS[prompt]['split']) # add wiki prompt splits as \"Other\" attribute\n",
    "KEPT_ATTR_TO_PROMPT_AND_SPLIT = {k: {p: v for p, v in d.items() if p.count('%') == 1} for k, d in KEPT_ATTR_TO_PROMPT_AND_SPLIT.items()}\n",
    "print(f'Total #entities={len(ALL_ENTITY_SPLITS)} #attributes={len(KEPT_ATTR_TO_PROMPT_AND_SPLIT)} #prompts={sum(map(len, ALL_ATTR_TO_PROMPTS.values()))} #wiki_prompts={len(WIKI_PROMPT_SPLITS)}')\n",
    "print(f'Kept #entities={len(KEPT_ENTITY_SPLITS)} #prompts={len(KEPT_PROMPT_SPLITS)}')\n",
    "for split in ('train', 'val', 'test'):\n",
    "  print(split, f'Kept #entities={len([k for k, v in KEPT_ENTITY_SPLITS.items() if v == split])}',\n",
    "               f'#prompts={len([k for k, v in KEPT_PROMPT_SPLITS.items() if v[1] == split])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AuDFPXkjNy-j",
    "outputId": "ab035725-a893-4e14-fda7-9516ba099a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2810\n",
      "Total #prompts=2810\n",
      "Set prompt_max_length=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [11:13<00:00, 15.31s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate outputs for all wiki inv prompts\n",
    "from sae_lens.sae_bench.utils.generation_utils import generate_batched\n",
    "\n",
    "skip_wiki_to_prompt = False\n",
    "filename_prompt_to_output = f'ravel_{model_name}_{ENTITY_TYPE}_wiki_prompt_to_output.json'\n",
    "\n",
    "if not skip_wiki_to_prompt:\n",
    "    wiki_prompts = [(t % e) for t, s_e in WIKI_PROMPT_SPLITS.items()\n",
    "                    for e in ([s_e['entity']] if s_e['entity']\n",
    "                            else [a for a in KEPT_ENTITY_SPLITS if KEPT_ENTITY_SPLITS[a] == 'train' or s_e['split'] == 'train'])\n",
    "                    ]\n",
    "    print(len(wiki_prompts))\n",
    "\n",
    "    wiki_prompt_and_output = generate_batched(\n",
    "        hf_model,\n",
    "        tokenizer,\n",
    "        wiki_prompts,\n",
    "        max_new_tokens=8,\n",
    "        batch_size=64)\n",
    "    wiki_prompt_to_output = {k: v[len(k):] for k, v in wiki_prompt_and_output}\n",
    "    json.dump(wiki_prompt_to_output, open(os.path.join(DATA_DIR, model_name, filename_prompt_to_output), \"w\"), ensure_ascii=False)\n",
    "else:\n",
    "    wiki_prompt_to_output = json.load(open(os.path.join(DATA_DIR, model_name, filename_prompt_to_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q8ZHekPHN6sB",
    "outputId": "5094bf7e-a1f5-4c1c-925f-f3ee42ba3cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2910\n"
     ]
    }
   ],
   "source": [
    "# Set of prompts with all possible outputs\n",
    "\n",
    "ALL_PROMPT_TO_OUTPUT = {**prompt_to_output, **wiki_prompt_to_output}\n",
    "\n",
    "print(len(ALL_PROMPT_TO_OUTPUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "k0u90Zo6Gu_W"
   },
   "outputs": [],
   "source": [
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "# from utils.intervention_utils import extract_label\n",
    "from sae_lens.sae_bench.utils.generate_ravel_instance import RAVELMetadata\n",
    "\n",
    "# def extract_label(string):\n",
    "#     delimiters = r\"[ \\-\\t,.\\n]\"\n",
    "#     return re.split(delimiters, string.strip())[0]\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_label(text):\n",
    "    tokens = re.split(r'([\"]|[.,;]\\s|\\n| \\(|\\sand)', text + ' ')\n",
    "    x = tokens[0]\n",
    "    digit_match = re.search(r'\\.\\d\\d', x)\n",
    "    if digit_match:\n",
    "        x = x[:digit_match.span(0)[1]]\n",
    "    gender_match = re.match(r'\\s?(his|her|himself|herself|she|he)[^\\w]', x)\n",
    "    if gender_match:\n",
    "        x = x[:gender_match.span(1)[1]]\n",
    "    if not x.strip():\n",
    "        x = ' '.join(text.split(' ')[:2]).rstrip('.,\"\\n')\n",
    "    assert x.strip()\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_first_token(x):\n",
    "  return re.split(r'[^\\w\\+\\-]', x.strip(), re.UNICODE)[0]\n",
    "\n",
    "\n",
    "def filter_inv_example(base_output, inv_output):\n",
    "  different_outputs = (get_first_token(base_output) !=\n",
    "                       get_first_token(inv_output))\n",
    "  valid_outputs = (\n",
    "      re.fullmatch(r'\\s?[a-z0-9.:\\-+]+', extract_label(base_output), re.IGNORECASE) and\n",
    "      re.fullmatch(r'\\s?[a-z0-9.:\\-+]+', extract_label(inv_output), re.IGNORECASE))\n",
    "  return valid_outputs and different_outputs\n",
    "\n",
    "\n",
    "FEATURE_TYPES = datasets.Features({\"input\": datasets.Value(\"string\"), \"label\": datasets.Value(\"string\"),\n",
    "                              \"source_input\": datasets.Value(\"string\"), \"source_label\": datasets.Value(\"string\"),\n",
    "                              \"inv_label\": datasets.Value(\"string\"),\n",
    "                              'split': datasets.Value(\"string\"), 'source_split': datasets.Value(\"string\"),\n",
    "                              'entity': datasets.Value(\"string\"), 'source_entity': datasets.Value(\"string\")})\n",
    "\n",
    "\n",
    "ravel_metadata = RAVELMetadata(\n",
    "    model_name,\n",
    "    KEPT_ENTITY_SPLITS,\n",
    "    KEPT_ATTR_TO_PROMPT_AND_SPLIT,\n",
    "    KEPT_PROMPT_SPLITS,\n",
    "    WIKI_PROMPT_SPLITS,\n",
    "    ALL_PROMPT_TO_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(KEPT_ENTITY_SPLITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Thailand'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_label(' Thailand.\\nThe distance from P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Su3jJN1iwK5h",
    "outputId": "5ee46517-fa94-482a-dcf9-f9cf83501a19"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'city to country: New Delhi is in India. Chota is in'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Take the first N examples only\u001b[39;00m\n\u001b[1;32m     12\u001b[0m first_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[0;32m---> 14\u001b[0m eval_split_to_raw_example \u001b[38;5;241m=\u001b[39m \u001b[43mgen_context_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mravel_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_label_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_example_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_inv_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfirst_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m eval_split_to_dataset \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     20\u001b[0m     split: Dataset\u001b[38;5;241m.\u001b[39mfrom_list(eval_split_to_raw_example[split][:first_n], features\u001b[38;5;241m=\u001b[39mFEATURE_TYPES)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m eval_split_to_raw_example}\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Compute stats.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/SAELens/sae_lens/sae_bench/utils/generate_ravel_instance.py:51\u001b[0m, in \u001b[0;36mgen_context_test_split\u001b[0;34m(metadata, extract_label_fn, filter_example_fn, first_n)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOther\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     49\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     50\u001b[0m base_task_inputs \u001b[38;5;241m=\u001b[39m [((prompt, entity),\n\u001b[0;32m---> 51\u001b[0m                      \u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_to_output\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     52\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m metadata\u001b[38;5;241m.\u001b[39mget_entities(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(base_task_inputs) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[1;32m     54\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSKIP - NOT ENOUGH BASE EXAMPLES: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubsplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'city to country: New Delhi is in India. Chota is in'"
     ]
    }
   ],
   "source": [
    "#@title Generate the Conetxt TEST/VAL Split\n",
    "\n",
    "# Context Split: All entities are in TRAIN, but all prompts are in test/dev\n",
    "\n",
    "import random\n",
    "\n",
    "from sae_lens.sae_bench.utils.generate_ravel_instance import gen_context_test_split\n",
    "\n",
    "TEST_TYPE = 'context'\n",
    "\n",
    "# Take the first N examples only\n",
    "first_n = 256\n",
    "\n",
    "eval_split_to_raw_example = gen_context_test_split(\n",
    "    ravel_metadata,\n",
    "    extract_label_fn=extract_label,\n",
    "    filter_example_fn=filter_inv_example,\n",
    "    first_n=first_n)\n",
    "eval_split_to_dataset = {\n",
    "    split: Dataset.from_list(eval_split_to_raw_example[split][:first_n], features=FEATURE_TYPES)\n",
    "    for split in eval_split_to_raw_example}\n",
    "\n",
    "# Compute stats.\n",
    "for split in eval_split_to_raw_example:\n",
    "  print('\\nSplit %s:\\nTotal %d examples, kept first %d examples, %d unique input values,  %d unique entities, %d unique output values' % (\n",
    "      repr(split), len(eval_split_to_raw_example[split]), len(eval_split_to_dataset[split]),\n",
    "      len(set([exp[x] for exp in eval_split_to_raw_example[split][:first_n] for x in ['input', 'source_input']])),\n",
    "      len(set([exp[x] for exp in eval_split_to_raw_example[split][:first_n] for x in ['entity', 'source_entity']])),\n",
    "      len(set([exp['inv_label'] for exp in eval_split_to_raw_example[split][:first_n]])),\n",
    "      # len(set([tokenizer('0' + exp['inv_label']).input_ids[3] for exp in eval_split_to_raw_example[split][:first_n]]))\n",
    "      ))\n",
    "  #for i, example in enumerate(eval_split_to_raw_example[split]):\n",
    "  #  print(example)\n",
    "  #  #print(tokenizer(example['input']).input_ids)\n",
    "  #  break\n",
    "  #for k in ('input', 'source_input'):\n",
    "  #  input_ids = tokenizer(example[k])['input_ids']\n",
    "  #  #print(k)\n",
    "  #  #print(input_ids)\n",
    "  #  print(list(zip([(32 - len(input_ids)) + i for i in range(len(input_ids))], tokenizer.batch_decode(input_ids))))\n",
    "for split in ('test', 'val'):\n",
    "  print(f'Split {split}: Total #subsplit={len([k for k in eval_split_to_raw_example if k.endswith(split)])} #Examples={sum(map(len, [v for k, v in eval_split_to_raw_example.items() if k.endswith(split)]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCqiWwopEC2_"
   },
   "outputs": [],
   "source": [
    "# Merge subsplits\n",
    "eval_split_to_raw_example_merged = collections.defaultdict(list)\n",
    "for split in eval_split_to_raw_example:\n",
    "  eval_split_to_raw_example_merged[re.sub(r'-causal|-output|-other', '', split)].extend(eval_split_to_raw_example[split])\n",
    "eval_split_to_raw_example = dict(eval_split_to_raw_example_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHSF9zO1QpLI"
   },
   "outputs": [],
   "source": [
    "output_json_path = os.path.join(DATA_DIR, f'{ravel_metadata.instance}/{ravel_metadata.instance}_{ENTITY_TYPE}_{TEST_TYPE}_test.json')\n",
    "print(output_json_path)\n",
    "json.dump(eval_split_to_raw_example, open(output_json_path, 'w'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cELK5Wck671X",
    "outputId": "3279061c-f90c-4f11-d7de-77331ec2b022"
   },
   "outputs": [],
   "source": [
    "#@title Generate the Entity TEST/VAL Split\n",
    "\n",
    "from utils.generate_ravel_instance import gen_entity_test_split\n",
    "\n",
    "TEST_TYPE = 'entity'\n",
    "\n",
    "# Take the first N examples only\n",
    "first_n = 128\n",
    "\n",
    "eval_split_to_raw_example = gen_entity_test_split(\n",
    "    ravel_metadata,\n",
    "    extract_label_fn=extract_label, filter_example_fn=filter_inv_example,\n",
    "    first_n=first_n)\n",
    "\n",
    "eval_split_to_dataset = {\n",
    "    split: Dataset.from_list(eval_split_to_raw_example[split][:first_n], features=FEATURE_TYPES)\n",
    "    for split in eval_split_to_raw_example}\n",
    "\n",
    "# Stats\n",
    "for split in eval_split_to_raw_example:\n",
    "  print('Split %s: Total %d examples, kept first %d examples, %d unique input values,  %d unique entities, %d unique output values' % (\n",
    "      repr(split), len(eval_split_to_raw_example[split]), len(eval_split_to_dataset[split]),\n",
    "      len(set([exp[x] for exp in eval_split_to_raw_example[split][:first_n] for x in ['input', 'source_input']])),\n",
    "      len(set([exp[x] for exp in eval_split_to_raw_example[split][:first_n] for x in ['entity', 'source_entity']])),\n",
    "      len(set([exp['inv_label'] for exp in eval_split_to_raw_example[split][:first_n]])),\n",
    "      # len(set([tokenizer('0' + exp['inv_label']).input_ids[3] for exp in eval_split_to_raw_example[split][:first_n]]))\n",
    "      ))\n",
    "  for i, example in enumerate(eval_split_to_raw_example[split]):\n",
    "    print(example)\n",
    "    #print(tokenizer(example['input']).input_ids)\n",
    "    break\n",
    "  for k in ('input', 'source_input'):\n",
    "    input_ids = tokenizer(example[k])['input_ids']\n",
    "    #print(k)\n",
    "    #print(input_ids)\n",
    "    print(list(zip([(32 - len(input_ids)) + i for i in range(len(input_ids))], tokenizer.batch_decode(input_ids))))\n",
    "for split in ('test', 'val'):\n",
    "  print(f'Split {split}: Total #subsplit={len([k for k in eval_split_to_raw_example if k.endswith(split)])} #Examples={sum(map(len, [v for k, v in eval_split_to_raw_example.items() if k.endswith(split)]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIui4buzFi5N"
   },
   "outputs": [],
   "source": [
    "# Merge subsplits\n",
    "eval_split_to_raw_example_merged = collections.defaultdict(list)\n",
    "for split in eval_split_to_raw_example:\n",
    "  eval_split_to_raw_example_merged[re.sub(r'-causal|-output|-other', '', split)].extend(eval_split_to_raw_example[split])\n",
    "eval_split_to_raw_example = dict(eval_split_to_raw_example_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45Xe-rvibqeQ"
   },
   "outputs": [],
   "source": [
    "output_json_path = os.path.join(DATA_DIR, f'{ravel_metadata.instance}/{ravel_metadata.instance}_{ENTITY_TYPE}_{TEST_TYPE}_test.json')\n",
    "print(output_json_path)\n",
    "json.dump(eval_split_to_raw_example, open(output_json_path, 'w'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HB1P3ZNziM7c",
    "outputId": "b80cd416-2c23-4d93-b2a1-d10036654b43"
   },
   "outputs": [],
   "source": [
    "#@title Generate train split (for models that use counterfactuals)\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "def gen_train_split(metadata, extract_label_fn, filter_example_fn, first_n=256):\n",
    "  split_to_raw_example = {}\n",
    "  # Group by attributes.\n",
    "  target_split = 'train'\n",
    "  for attr, prompt_to_split in metadata.attr_to_prompt.items():\n",
    "      base_prompt_candiates = [p for p, s in prompt_to_split.items() if s == target_split]\n",
    "      base_task_inputs = [\n",
    "          ((prompt, entity), metadata.prompt_to_output[prompt % entity])\n",
    "          for entity in metadata.get_entities(target_split)\n",
    "          for prompt in random.sample(\n",
    "              base_prompt_candiates, k=min(2, len(base_prompt_candiates)))]\n",
    "      source_task_inputs = [\n",
    "          ((source_prompt, entity), metadata.prompt_to_output[source_prompt % entity])\n",
    "          for source_prompt, (source_attr, source_split) in KEPT_PROMPT_SPLITS.items()\n",
    "          if source_split == target_split and source_attr != 'Other'\n",
    "          for entity in metadata.sample_entities(target_split, k=1)\n",
    "      ]\n",
    "      wiki_source_task_inputs = [\n",
    "          ((source_prompt, entity), metadata.prompt_to_output[source_prompt % entity])\n",
    "          for source_prompt, split_and_arg in metadata.entity_prompt_to_split.items()\n",
    "          if split_and_arg['split'] == target_split\n",
    "          for entity in ([split_and_arg['entity']] if split_and_arg['entity']\n",
    "                         else metadata.sample_entities(target_split, k=1))\n",
    "      ]\n",
    "      source_task_inputs = source_task_inputs + wiki_source_task_inputs\n",
    "      if len(base_task_inputs) < 5 or len(source_task_inputs) < 5:\n",
    "        continue\n",
    "      print(attr, target_split, len(base_task_inputs), len(source_task_inputs), len(wiki_source_task_inputs))\n",
    "      split_to_raw_example[f'{attr}-{target_split}'] = []\n",
    "      for (p, a), v in base_task_inputs:\n",
    "        source_input_candiates = [x for x in source_task_inputs if filter_example_fn(v, metadata.prompt_to_output[p % x[0][1]])]\n",
    "        #print(len(source_input_candiates), v)\n",
    "        split_to_raw_example[f'{attr}-{target_split}'].extend([{\n",
    "          'input': p % a, 'label': extract_label_fn(v),\n",
    "          'source_input': s_p % s_a, 'source_label': extract_label_fn(source_v),\n",
    "          'inv_label': extract_label_fn(metadata.prompt_to_output[p % s_a]),\n",
    "          'split': p, 'source_split': s_p,\n",
    "          'entity': a, 'source_entity': s_a}\n",
    "        for (s_p, s_a), source_v in random.sample(source_input_candiates, k=min(len(source_input_candiates), round(first_n / len(base_task_inputs))))\n",
    "        if filter_example_fn(v, metadata.prompt_to_output[p % s_a]) and re.search('\\w+', source_v)\n",
    "      ])\n",
    "  split_to_raw_example = {k: v for k, v in split_to_raw_example.items() if len(v) > 0}\n",
    "  return split_to_raw_example\n",
    "\n",
    "\n",
    "# Take the first N examples only\n",
    "first_n = 10240\n",
    "\n",
    "split_to_raw_example = gen_train_split(\n",
    "    ravel_metadata,\n",
    "    extract_label_fn=extract_label,\n",
    "    filter_example_fn=filter_inv_example,\n",
    "    first_n=first_n)\n",
    "\n",
    "# Stats\n",
    "for split in split_to_raw_example:\n",
    "  print('Split %s: Total %d examples, kept first %d examples, %d unique input values,  %d unique entities, %d unique output values' % (\n",
    "      repr(split), len(split_to_raw_example[split]), len(split_to_raw_example[split]),\n",
    "      len(set([exp[x] for exp in split_to_raw_example[split][:first_n] for x in ['input', 'source_input']])),\n",
    "      len(set([exp[x] for exp in split_to_raw_example[split][:first_n] for x in ['entity', 'source_entity']])),\n",
    "      len(set([exp['inv_label'] for exp in split_to_raw_example[split][:first_n]])),\n",
    "      # len(set([tokenizer('0' + exp['inv_label']).input_ids[3] for exp in split_to_raw_example[split][:first_n]]))\n",
    "      ))\n",
    "  for i, example in enumerate(split_to_raw_example[split]):\n",
    "    print(example)\n",
    "    #print(tokenizer(example['input']).input_ids)\n",
    "    break\n",
    "  #for k in ('input', 'source_input'):\n",
    "  #  input_ids = tokenizer(example[k])['input_ids']\n",
    "  #  #print(k)\n",
    "  #  #print(input_ids)\n",
    "  #  print(list(zip([(32 - len(input_ids)) + i for i in range(len(input_ids))], tokenizer.batch_decode(input_ids))))\n",
    "for split in ('train',):\n",
    "  print(f'Split {split}: Total #subsplit={len([k for k in split_to_raw_example if k.endswith(split)])} #Examples={sum(map(len, [v for k, v in split_to_raw_example.items() if k.endswith(split)]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-a23pstkqr6U"
   },
   "outputs": [],
   "source": [
    "json_path = os.path.join(DATA_DIR, f'{ravel_metadata.instance}/{ravel_metadata.instance}_{ENTITY_TYPE}_train.json')\n",
    "print(json_path)\n",
    "json.dump(split_to_raw_example, open(json_path, 'w'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6yj87A4_OoW7",
    "outputId": "b6042ddc-02ae-4e8e-cf0a-48e8b95cff4c"
   },
   "outputs": [],
   "source": [
    "#@title Postprocess labels\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "# from intervention_utils import extract_label\n",
    "\n",
    "\n",
    "entity_type = 'city'\n",
    "instance =  model_name\n",
    "version = ''\n",
    "\n",
    "\n",
    "attribute_to_prompts = json.load(open(os.path.join(DATA_DIR + version, 'base', f'ravel_{entity_type}_attribute_to_prompts.json')))\n",
    "\n",
    "\n",
    "json_path = os.path.join(DATA_DIR + version, f'{instance}/{instance}_{entity_type}_context_test.json')\n",
    "split_to_raw_example = json.load(open(json_path, 'r'))\n",
    "print(len(split_to_raw_example))\n",
    "\n",
    "all_labels = set()\n",
    "for split in split_to_raw_example:\n",
    "  for i in range(len(split_to_raw_example[split])):\n",
    "    if split.split('-')[0] in ['Latitude', 'Longitude'] or  split.split('-')[0] in attribute_to_prompts['Latitude'] or split.split('-')[0] in attribute_to_prompts['Longitude']:\n",
    "      # Keep only the integer part.\n",
    "      split_to_raw_example[split][i]['inv_label'] = split_to_raw_example[split][i]['inv_label'].replace('°', '.').split('.')[0]\n",
    "      split_to_raw_example[split][i]['label'] = split_to_raw_example[split][i]['label'].replace('°', '.').split('.')[0]\n",
    "    all_labels.add(split_to_raw_example[split][i]['inv_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCOrt1xqS0L9"
   },
   "outputs": [],
   "source": [
    "json.dump(split_to_raw_example, open(json_path, 'w'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WaKW4KTgiOO1",
    "outputId": "dc973865-d7e3-4291-c78b-2cab903f4233"
   },
   "outputs": [],
   "source": [
    "sorted(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7jT94__J6Jf",
    "outputId": "635e8f9e-6286-49d1-a864-b42c0d2c6542"
   },
   "outputs": [],
   "source": [
    "#@title Intervention locations for all possible prompts\n",
    "\n",
    "SPLIT_TO_INV_POSITION = {}\n",
    "\n",
    "all_prompt_templates = {p for p in WIKI_PROMPT_SPLITS}\n",
    "all_prompt_templates.update({v for vs in ALL_ATTR_TO_PROMPTS.values() for v in vs})\n",
    "print(len(all_prompt_templates))\n",
    "\n",
    "for prompt_template in all_prompt_templates:\n",
    "  if prompt_template.count('%s') != 1:\n",
    "    continue\n",
    "  print(prompt_template)\n",
    "  prompt_input = prompt_template.replace('%s', '000000', 1)\n",
    "  input_ids = tokenizer(prompt_input)['input_ids']\n",
    "  toks = tokenizer.batch_decode(input_ids)\n",
    "  for i in range(-1, -len(toks), -1):\n",
    "    if toks[i] == '0' and toks[i - 1] == '0' and toks[i - 2] == '0' and toks[i - 3] == '0':\n",
    "      break\n",
    "  SPLIT_TO_INV_POSITION[prompt_template] = i\n",
    "  print(i, list(zip([(32 - len(input_ids)) + i for i in range(len(input_ids))], toks)))\n",
    "\n",
    "print(min(SPLIT_TO_INV_POSITION.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsjBIBi05vtL"
   },
   "outputs": [],
   "source": [
    "version = ''\n",
    "json.dump(SPLIT_TO_INV_POSITION,\n",
    "          open(os.path.join(DATA_DIR + version, instance, f'{instance}_{entity_type}_prompt_to_entity_position.json'), 'w'),\n",
    "          ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4r6ETYXK0Mhc"
   },
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resid_post_activations(nnsight_model, layer_idx, encoded_input):\n",
    "    submodule = nnsight_model.model.layers[layer_idx]\n",
    "    with torch.no_grad(), nnsight_model.trace(\n",
    "        encoded_input.input_ids.to(device),\n",
    "        attention_mask=encoded_input.attention_mask.to(device), \n",
    "        **nnsight_tracer_kwargs):\n",
    "        output = submodule.output[0].save()\n",
    "    return output\n",
    "\n",
    "# # Test the function\n",
    "# prompt = [\"Hello, my name is\", \"hello\"]\n",
    "# tok = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "\n",
    "# out = get_resid_post_activations(\n",
    "#     nnsight_model,\n",
    "#     layer_idx=0,\n",
    "#     encoded_input=tok['input_ids'],\n",
    "# )\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GaHAwei3-zA1"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import re\n",
    "import pickle as pkl\n",
    "\n",
    "# from extract_neuron_activations import get_representations_across_layers_llama\n",
    "\n",
    "\n",
    "def extract_ravel_entity_features(entity_to_split, attribute_to_prompt_and_split,\n",
    "                                  layer, output_path, batch_size=128, placeholder='%s'):\n",
    "  print(output_path)\n",
    "  f_out = h5py.File(output_path, \"a\")\n",
    "  # Generate prompts.\n",
    "  splits = {'train': ('train', 'train'),\n",
    "                 'val_entity': ('val', 'train'),\n",
    "                 'val_context': ('train', 'val'),}\n",
    "  for split_name, (entity_split, prompt_split) in splits.items():\n",
    "    for attr, prompt_to_split in attribute_to_prompt_and_split.items():\n",
    "      inputs, entities, templates = zip(*[(p[:p.index(placeholder)] + e, e, p)\n",
    "          for p in prompt_to_split if prompt_to_split[p] == prompt_split\n",
    "          for e in entity_to_split if entity_to_split[e] == entity_split])\n",
    "      all_features = []\n",
    "      for b_i in range(0, len(inputs), batch_size):\n",
    "        input_batch = inputs[b_i:b_i+batch_size]\n",
    "        encoded_input = tokenizer(\n",
    "            input_batch, padding=\"max_length\", max_length=INPUT_MAX_LEN,\n",
    "            return_tensors=\"pt\", truncation=True)\n",
    "        with torch.no_grad():\n",
    "          # outputs = get_representations_across_layers_llama(\n",
    "          #     model.model, encoded_input, layer_index=layer)[f'layer_{layer}-block_output']\n",
    "          outputs = get_resid_post_activations(nnsight_model, layer, encoded_input)\n",
    "          for i in range(len(input_batch)):\n",
    "            all_features.append(outputs[i:i+1, -1, :].to(torch.float16).cpu().numpy())\n",
    "      print(attr, split_name, np.concatenate(all_features).shape)\n",
    "      f_out[f'{attr}-{split_name}'] = np.concatenate(all_features)\n",
    "      f_out[f'{attr}-{split_name}' + '_input'] = np.void(pkl.dumps(inputs))\n",
    "      f_out[f'{attr}-{split_name}' + '_template'] = np.void(pkl.dumps(templates))\n",
    "      f_out[f'{attr}-{split_name}' + '_entity'] = np.void(pkl.dumps(entities))\n",
    "  f_out.flush()\n",
    "  f_out.close()\n",
    "\n",
    "\n",
    "INPUT_MAX_LEN = 48\n",
    "\n",
    "\n",
    "for layer in [10, 14]:\n",
    "  output_path = os.path.join(DATA_DIR, model_name, f'ravel_{entity_type}_{model_name}_layer{layer}_representation.hdf5')\n",
    "  extract_ravel_entity_features(\n",
    "      KEPT_ENTITY_SPLITS, KEPT_ATTR_TO_PROMPT_AND_SPLIT,\n",
    "      layer, output_path, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
