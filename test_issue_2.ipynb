{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/main/demos/Hooked_SAE_Transformer_Demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HookedSAETransformer Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HookedSAETransformer is a lightweight extension of HookedTransformer that allows you to \"splice in\" Sparse Autoencoders. This makes it easy to do exploratory analysis such as: running inference with SAEs attached, caching SAE feature activations, and intervening on SAE activations with hooks.\n",
    "\n",
    "I (Connor Kissane) implemented this to accelerate research on [Attention SAEs](https://www.lesswrong.com/posts/DtdzGwFh9dCfsekZZ/sparse-autoencoders-work-on-attention-layer-outputs) based on suggestions from Arthur Conmy and Neel Nanda, and found that it was well worth the time and effort. I hope other researchers will also find the library useful! This notebook demonstrates how it works and how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rt/vlzhnvkj6s51xk5xshx4ldqc0000gn/T/ipykernel_17374/1103738670.py:16: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/var/folders/rt/vlzhnvkj6s51xk5xshx4ldqc0000gn/T/ipykernel_17374/1103738670.py:17: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
    "DEVELOPMENT_MODE = False\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "    %pip install git+https://github.com/jbloomAus/SAELens\n",
    "  \n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "    ipython.magic(\"load_ext autoreload\")\n",
    "    ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformer_lens.utils as utils\n",
    "\n",
    "import plotly.express as px\n",
    "import tqdm\n",
    "from functools import partial\n",
    "import einops\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "update_layout_set = {\n",
    "    \"xaxis_range\", \"yaxis_range\", \"hovermode\", \"xaxis_title\", \"yaxis_title\", \"colorbar\", \"colorscale\", \"coloraxis\",\n",
    "     \"title_x\", \"bargap\", \"bargroupgap\", \"xaxis_tickformat\", \"yaxis_tickformat\", \"title_y\", \"legend_title_text\", \"xaxis_showgrid\",\n",
    "     \"xaxis_gridwidth\", \"xaxis_gridcolor\", \"yaxis_showgrid\", \"yaxis_gridwidth\"\n",
    "}\n",
    "\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    if isinstance(tensor, list):\n",
    "        tensor = torch.stack(tensor)\n",
    "    kwargs_post = {k: v for k, v in kwargs.items() if k in update_layout_set}\n",
    "    kwargs_pre = {k: v for k, v in kwargs.items() if k not in update_layout_set}\n",
    "    if \"facet_labels\" in kwargs_pre:\n",
    "        facet_labels = kwargs_pre.pop(\"facet_labels\")\n",
    "    else:\n",
    "        facet_labels = None\n",
    "    if \"color_continuous_scale\" not in kwargs_pre:\n",
    "        kwargs_pre[\"color_continuous_scale\"] = \"RdBu\"\n",
    "    fig = px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0,labels={\"x\":xaxis, \"y\":yaxis}, **kwargs_pre).update_layout(**kwargs_post)\n",
    "    if facet_labels:\n",
    "        for i, label in enumerate(facet_labels):\n",
    "            fig.layout.annotations[i]['text'] = label\n",
    "\n",
    "    fig.show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, return_fig=False, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    fig = px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs)\n",
    "    if return_fig:\n",
    "        return fig\n",
    "    fig.show(renderer)\n",
    "\n",
    "from typing import List\n",
    "def show_avg_logit_diffs(x_axis: List[str], per_prompt_logit_diffs: List[torch.tensor]):\n",
    "\n",
    "\n",
    "    y_data = [per_prompt_logit_diff.mean().item() for per_prompt_logit_diff in per_prompt_logit_diffs]\n",
    "    error_y_data = [per_prompt_logit_diff.std().item() for per_prompt_logit_diff in per_prompt_logit_diffs] \n",
    "\n",
    "    fig = go.Figure(data=[go.Bar(\n",
    "        x=x_axis,\n",
    "        y=y_data,\n",
    "        error_y=dict(\n",
    "            type='data',  # specifies that the actual values are given\n",
    "            array=error_y_data,  # the magnitudes of the errors\n",
    "            visible=True  # make error bars visible\n",
    "        ),\n",
    "    )])\n",
    "\n",
    "    # Customize layout\n",
    "    fig.update_layout(title_text=f'Logit Diff after Interventions',\n",
    "                    xaxis_title_text='Intervention',\n",
    "                    yaxis_title_text='Logit diff',\n",
    "                    plot_bgcolor='white')\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1130e3b00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else: \n",
    "    device = \"cpu\"\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Running Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like a [HookedTransformer](https://TransformerLensOrg.github.io/TransformerLens/generated/demos/Main_Demo.html#Loading-and-Running-Models), we can load in any model that's supported in TransformerLens with the `HookedSAETransformer.from_pretrained(MODEL_NAME)`. In this demo we'll use GPT-2 small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /Users/curttigges/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb71929ac554c199903a7aaf11f95cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-2b into HookedTransformer\n",
      "Moving model to device:  mps\n"
     ]
    }
   ],
   "source": [
    "from sae_lens import HookedSAETransformer\n",
    "model: HookedSAETransformer = HookedSAETransformer.from_pretrained(\"google/gemma-2-2b\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<bos>', ' did', ' it', ' come', ' from', ' and'],\n",
       " ['<bos>', ' large', ' parts', ' warmer', ' than', ' -'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = model.to_tokens(\"<bos> did it come from and\", prepend_bos=False)\n",
    "tokens2 = model.to_tokens(\"<bos> male bonding based on practical jokes and humour, thanks largely to the influence of Lee Majors. He remembers Lee as being very athletically inclined and always eager to perform as many of the show’s stunts as he possibly could himself. Richard Anderson he remembers as someone who was obsessed about topping up his tan between takes, but he’s impressed about how Anderson developed the relatively thankless role of Oscar Goldman and made him into such an iconic part of the show. He talks about coordinating his role as Rudy Wells in both “The Six Million Dollar Man” and “The Bionic Woman”, and sometimes getting confused about which lines he was\", prepend_bos=False)\n",
    "tokens3 = model.to_tokens(\"<bos> large parts warmer than -\", prepend_bos=False)\n",
    "model.to_str_tokens(tokens), model.to_str_tokens(tokens3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens import SAE\n",
    "\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release = \"gemma-scope-2b-pt-res-canonical\", # see other options in sae_lens/pretrained_saes.yaml\n",
    "    sae_id = \"layer_20/width_65k/canonical\", # won't always be a hook point\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attached SAEs after add_sae {'blocks.20.hook_resid_post': SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "model.add_sae(sae)\n",
    "print(\"Attached SAEs after add_sae\", model.acts_to_saes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Feature Id: %{x}<br>Prompt: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "723",
          "3458",
          "3869",
          "7034",
          "7559",
          "8351",
          "8680",
          "11559",
          "12148",
          "13014",
          "13346",
          "16297",
          "16652",
          "17211",
          "17491",
          "20192",
          "20804",
          "22028",
          "22860",
          "23034",
          "23553",
          "24023",
          "26662",
          "26761",
          "26839",
          "28535",
          "28996",
          "29435",
          "29852",
          "31016",
          "33020",
          "33077",
          "35570",
          "38580",
          "38929",
          "42326",
          "42973",
          "44226",
          "45014",
          "45257",
          "46929",
          "49337",
          "52797",
          "53122",
          "53864",
          "60109",
          "60940",
          "61814"
         ],
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           62.56865,
           17.735497,
           24.476856,
           5.8769464,
           20.013083,
           20.345306,
           6.3120365,
           11.309141,
           10.026488,
           10.088806,
           11.518533,
           7.5343075,
           5.1573243,
           7.2939105,
           6.440702,
           37.934784,
           4.7466044,
           6.6034913,
           12.980351,
           9.823178,
           5.7560472,
           85.889275,
           5.0215864,
           19.289728,
           13.787289,
           7.085516,
           20.65082,
           13.878255,
           4.8522997,
           13.891632,
           36.180134,
           8.157822,
           4.947086,
           4.923641,
           9.161907,
           8.323687,
           5.893614,
           21.145535,
           7.5814676,
           60.860214,
           14.12685,
           5.3054833,
           7.0588,
           60.36314,
           7.398574,
           22.551054,
           5.834626,
           9.65087
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 0,
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Activations of Live SAE features at L5 S2 position per prompt"
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Feature Id"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Prompt"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer = 20\n",
    "_, cache = model.run_with_cache(tokens3)\n",
    "sae_acts = cache[utils.get_act_name('resid_post', layer) + \".hook_sae_acts_post\"][:, 1, :]\n",
    "\n",
    "live_feature_mask = sae_acts > 0\n",
    "live_feature_union = live_feature_mask.any(dim=0)\n",
    "\n",
    "\n",
    "imshow(\n",
    "    sae_acts[:, live_feature_union],\n",
    "    title = \"Activations of Live SAE features at L5 S2 position per prompt\",\n",
    "    xaxis=\"Feature Id\", yaxis=\"Prompt\",\n",
    "    x=list(map(str, live_feature_union.nonzero().flatten().tolist())),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000, 37.9348,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000], device='mps:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_acts[0, 20190:20200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(118, device='mps:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_acts_cnt = (sae_acts[0, :] > 0).sum()\n",
    "sae_acts_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with hooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can also use `run_with_hooks` and intervene on the added SAE's activations. To show a more complicated intervention, we'll try path patching the feature from the S-inhibition head's value vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_use_split_qkv_input(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_patch_v_input(v_input, hook, feature_dirs, pos, head_index):\n",
    "    v_input[:, pos, head_index, :] = v_input[:, pos, head_index, :] - feature_dirs\n",
    "    return v_input\n",
    "\n",
    "\n",
    "s_inhib_heads = [(7, 3), (7, 9), (8,6), (8,10)]\n",
    "\n",
    "results = torch.zeros(tokens.shape[0], all_live_features.shape[0])\n",
    "\n",
    "W_O_cat = einops.rearrange(\n",
    "    model.W_O,\n",
    "    \"n_layers n_heads d_head d_model -> n_layers (n_heads d_head) d_model\"\n",
    ")\n",
    "\n",
    "for feature_id in tqdm.tqdm(all_live_features):\n",
    "    feature_id = feature_id.item()\n",
    "    feature_acts = cache[utils.get_act_name('z', abl_layer) + \".hook_sae_acts_post\"][:, abl_pos, feature_id] # [batch]\n",
    "    feature_dirs = (feature_acts.unsqueeze(-1) * sae.W_dec[feature_id]) @ W_O_cat[abl_layer]\n",
    "    hook_fns = [\n",
    "        (utils.get_act_name('v_input', layer), partial(path_patch_v_input, feature_dirs=feature_dirs, pos=abl_pos, head_index=head)) for (layer, head) in s_inhib_heads\n",
    "    ]\n",
    "    path_patched_logits = model.run_with_hooks(\n",
    "        tokens,\n",
    "        return_type=\"logits\",\n",
    "        fwd_hooks=hook_fns\n",
    "    )\n",
    "\n",
    "    path_patched_logit_diff = logits_to_ave_logit_diff(path_patched_logits, answer_tokens, per_prompt=True)\n",
    "    results[:, fid_to_idx[feature_id]] = path_patched_logit_diff - clean_sae_baseline_per_prompt\n",
    "\n",
    "imshow(\n",
    "    results, \n",
    "    title=f\"Change in logit diff when path patching features from S_inhibition heads values per prompts\",\n",
    "    xaxis=\"Feature Id\", yaxis=\"Prompt Idx\", x=list(map(str, all_live_features.tolist()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset SAEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One major footgun is forgetting about an SAE that you previously attached with `add_sae`. Similar to TransformerLens `reset_hooks`, you can always reset SAEs you've added with `model.reset_saes()`. You can also pass in a list of activation names to only reset a subset of attached SAEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Attached SAEs before reset_saes:\", model.acts_to_saes)\n",
    "model.reset_saes()\n",
    "print(\"Attached SAEs after reset_saes:\", model.acts_to_saes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the HookedSAETransformer API is generally designed to closely match TransformerLens hooks API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent exciting work from [Marks et al.](https://arxiv.org/abs/2403.19647v2) demonstrated the use of \"error nodes\" in SAE circuit analysis. The idea is that for some input activation x, SAE(x) = x_reconstruct is an approximation of x, but we can define an error_term such that x = x_reconstruct + error_term.\n",
    "\n",
    "This seems useful: instead of replacing x with x_reconstruct, which might break everything and make our circuit analysis janky, we can just re-write x as a function of the SAE features, bias, and error term, which gives us access to all of the SAE features but without breaking performance. \n",
    "\n",
    "Additionally, we can compare interventions on SAE features to the same intervention on the error term to get a better sense of how much the SAE features have actually captured.\n",
    "\n",
    "To use error terms with SAEs, you can set `sae.use_error_term = True`. Note this is set to False by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "l5_sae = hook_name_to_sae[utils.get_act_name('z', 5)]\n",
    "l5_sae_with_error = copy.deepcopy(l5_sae)\n",
    "l5_sae_with_error.use_error_term=True\n",
    "model.add_sae(l5_sae_with_error)\n",
    "print(\"Attached SAEs after adding l5_sae_with_error:\", model.acts_to_saes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the output of each attached SAE will be SAE(x) + error_term = x. We can sanity check this by confirming that running with SAEs produces the same logits without SAEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_with_saes = model(tokens)\n",
    "logit_diff_with_saes = logits_to_ave_logit_diff(logits_with_saes, answer_tokens)\n",
    "\n",
    "assert torch.allclose(logits_with_saes, original_logits, atol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare ablations of each feature to ablating the error node. We'll start by ablating each feature on each prompt, and then the error nodes. We'll append the effects from ablating error nodes to the rightmost column on the heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablate_sae_feature(sae_acts, hook, pos, feature_id):\n",
    "    if pos is None:\n",
    "        sae_acts[:, :, feature_id] = 0.\n",
    "    else:\n",
    "        sae_acts[:, pos, feature_id] = 0.\n",
    "    return sae_acts\n",
    "\n",
    "layer = 5\n",
    "hooked_encoder = model.acts_to_saes[utils.get_act_name('z', layer)]\n",
    "all_live_features = torch.arange(hooked_encoder.cfg.d_sae)[live_feature_union.cpu()]\n",
    "\n",
    "causal_effects = torch.zeros((len(prompts), all_live_features.shape[0]))\n",
    "fid_to_idx = {fid.item(): idx for idx, fid in enumerate(all_live_features)}\n",
    "\n",
    "\n",
    "abl_layer, abl_pos  = 5, 10\n",
    "for feature_id in tqdm.tqdm(all_live_features):\n",
    "    feature_id = feature_id.item()\n",
    "    abl_feature_logits = model.run_with_hooks(\n",
    "        tokens,\n",
    "        return_type=\"logits\",\n",
    "        fwd_hooks=[(utils.get_act_name('z', abl_layer) + \".hook_sae_acts_post\", partial(ablate_sae_feature, pos=abl_pos, feature_id=feature_id))]\n",
    "    ) # [batch, seq, vocab]\n",
    "    \n",
    "    abl_feature_logit_diff = logits_to_ave_logit_diff(abl_feature_logits, answer_tokens, per_prompt=True) # [batch]\n",
    "    causal_effects[:, fid_to_idx[feature_id]] = abl_feature_logit_diff - original_per_prompt_logit_diff\n",
    "\n",
    "def able_sae_error(sae_error, hook, pos):\n",
    "    if pos is None:\n",
    "        sae_error = 0.\n",
    "    else:\n",
    "        sae_error[:, pos, ...] = 0.\n",
    "    return sae_error\n",
    "\n",
    "\n",
    "abl_error_logits = model.run_with_hooks(\n",
    "    tokens,\n",
    "    return_type=\"logits\",\n",
    "    fwd_hooks=[(utils.get_act_name('z', abl_layer) + \".hook_sae_error\", partial(able_sae_error, pos=abl_pos))]\n",
    ") # [batch, seq, vocab]\n",
    "\n",
    "abl_error_logit_diff = logits_to_ave_logit_diff(abl_error_logits, answer_tokens, per_prompt=True) # [batch]\n",
    "error_abl_effect = abl_error_logit_diff - original_per_prompt_logit_diff\n",
    "\n",
    "\n",
    "causal_effects_with_error = torch.cat([causal_effects, error_abl_effect.unsqueeze(-1).cpu()], dim=-1)\n",
    "imshow(causal_effects_with_error, title=f\"Change in logit diff when ablating L{abl_layer} SAE features for all prompts at pos {abl_pos}\", xaxis=\"Feature Idx\", yaxis=\"Prompt Idx\", x=list(map(str, all_live_features.tolist()))+[\"error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that on some prompts, ablating the error term (right most column) does have a non trivial effect on the logit diff, although I don't see a clear pattern. It seems useful to include this term when doing causal interventions to get a better sense of how much the SAE features are actually explaining. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribution patching "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Both [Anthropic](https://transformer-circuits.pub/2024/march-update/index.html#feature-heads) and [Marks et al](https://arxiv.org/abs/2403.19647v2). also demonstrated the use of gradient based attribution techniques as a substitute for activation patching on SAE features. The key idea is that patching / ablations (as we did above) can be slow, as it requires a new forward pass for each patch. This seems especially problematic when dealing with SAEs with tens of thousands of features per activation. They find that gradient based attribution techniques like [attribution patching](https://www.neelnanda.io/mechanistic-interpretability/attribution-patching) are good approximations, allowing for more efficient and scalable circuit analysis with SAEs.\n",
    "\n",
    "With `HookedSAETransformer`, added SAEs are automatically spliced into the computational graph, allowing us to implement this easily. Let's implement attribution patching for every L5 SAE feature to find causally relevant SAE features with just one forward and one backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import ActivationCache\n",
    "filter_sae_acts = lambda name: (\"hook_sae_acts_post\" in name)\n",
    "def get_cache_fwd_and_bwd(model, tokens, metric):\n",
    "    model.reset_hooks()\n",
    "    cache = {}\n",
    "    def forward_cache_hook(act, hook):\n",
    "        cache[hook.name] = act.detach()\n",
    "    model.add_hook(filter_sae_acts, forward_cache_hook, \"fwd\")\n",
    "\n",
    "    grad_cache = {}\n",
    "    def backward_cache_hook(act, hook):\n",
    "        grad_cache[hook.name] = act.detach()\n",
    "    model.add_hook(filter_sae_acts, backward_cache_hook, \"bwd\")\n",
    "\n",
    "    value = metric(model(tokens))\n",
    "    print(value)\n",
    "    value.backward()\n",
    "    model.reset_hooks()\n",
    "    return value.item(), ActivationCache(cache, model), ActivationCache(grad_cache, model)\n",
    "\n",
    "\n",
    "BASELINE = original_per_prompt_logit_diff\n",
    "def ioi_metric(logits, answer_tokens=answer_tokens):\n",
    "    return (logits_to_ave_logit_diff(logits, answer_tokens, per_prompt=True) - BASELINE).sum()\n",
    "\n",
    "clean_tokens = tokens.clone()\n",
    "clean_value, clean_cache, clean_grad_cache = get_cache_fwd_and_bwd(model, clean_tokens, ioi_metric)\n",
    "print(\"Clean Value:\", clean_value)\n",
    "print(\"Clean Activations Cached:\", len(clean_cache))\n",
    "print(\"Clean Gradients Cached:\", len(clean_grad_cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_patch_sae_acts(\n",
    "        clean_cache: ActivationCache, \n",
    "        clean_grad_cache: ActivationCache,\n",
    "        site: str, layer: int\n",
    "    ):\n",
    "    clean_sae_acts_post = clean_cache[utils.get_act_name(site, layer) + \".hook_sae_acts_post\"] \n",
    "    clean_grad_sae_acts_post = clean_grad_cache[utils.get_act_name(site, layer) + \".hook_sae_acts_post\"] \n",
    "    sae_act_attr = clean_grad_sae_acts_post * (0 - clean_sae_acts_post)\n",
    "    return sae_act_attr\n",
    "\n",
    "site = \"z\"\n",
    "layer = 5\n",
    "sae_act_attr = attr_patch_sae_acts(clean_cache, clean_grad_cache, site, layer)\n",
    "\n",
    "imshow(\n",
    "    sae_act_attr[:, s2_pos, all_live_features],\n",
    "    title=\"attribution patching\",\n",
    "    xaxis=\"Feature Idx\", yaxis=\"Prompt Idx\", x=list(map(str, all_live_features.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = scatter(\n",
    "    y=sae_act_attr[:, s2_pos, all_live_features].flatten(), \n",
    "    x=causal_effects.flatten(),\n",
    "    title=\"Attribution vs Activation Patching Per SAE feature (L5 S2 Pos, all prompts)\",\n",
    "    xaxis=\"Activation Patch\",\n",
    "    yaxis=\"Attribution Patch\",\n",
    "    return_fig=True\n",
    ")\n",
    "fig.add_shape(\n",
    "    type='line',\n",
    "    x0=causal_effects.min(),\n",
    "    y0=causal_effects.min(),\n",
    "    x1=causal_effects.max(),\n",
    "    y1=causal_effects.max(),\n",
    "    line=dict(\n",
    "        color='gray',\n",
    "        width=1,\n",
    "        dash='dot'\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
